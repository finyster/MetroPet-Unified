# build_vector_index.py

import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import config
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def build_and_save_index():
    """
    è®€å–æ‰€æœ‰æ¨™æº–åŒ–å¾Œçš„ç«™åï¼Œä½¿ç”¨ SentenceTransformer å°‡å…¶ç·¨ç¢¼ç‚ºå‘é‡ï¼Œ
    ç„¶å¾Œå»ºç«‹ä¸€å€‹ FAISS ç´¢å¼•ä¸¦å°‡å…¶èˆ‡ç«™ååˆ—è¡¨ä¸€èµ·ä¿å­˜ã€‚
    """
    logger.info("--- ğŸš€ é–‹å§‹å»ºç«‹å‘é‡æœå°‹ç´¢å¼• ---")

    # 1. è¼‰å…¥ station_manager å·²è™•ç†å¥½çš„ç«™é»è³‡æ–™
    if not os.path.exists(config.STATION_DATA_PATH):
        logger.error(f"âŒ ç«™é»è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨: {config.STATION_DATA_PATH}")
        logger.error("è«‹å…ˆåŸ·è¡Œ build_database.py ä¾†ç”Ÿæˆç«™é»è³‡æ–™ã€‚")
        return

    with open(config.STATION_DATA_PATH, 'r', encoding='utf-8') as f:
        station_map = json.load(f)
    
    # æˆ‘å€‘åªéœ€è¦ station_map ä¸­çš„ã€Œéµã€(ä¹Ÿå°±æ˜¯æ‰€æœ‰æ¨™æº–åŒ–å¾Œçš„ç«™åã€è‹±æ–‡åã€åˆ¥å)
    station_names = list(station_map.keys())
    if not station_names:
        logger.error("âŒ ç«™é»è³‡æ–™ä¸­æ²’æœ‰å¯ä¾›ç´¢å¼•çš„ç«™åã€‚")
        return
    
    logger.info(f"âœ… æˆåŠŸè¼‰å…¥ {len(station_names)} å€‹ç«™å/åˆ¥åã€‚")

    # 2. è¼‰å…¥é è¨“ç·´çš„èªæ„æ¨¡å‹
    #    'distiluse-base-multilingual-cased-v1' æ˜¯ä¸€å€‹æ”¯æ´å¤šèªè¨€çš„å„ªç§€æ¨¡å‹
    logger.info("â³ æ­£åœ¨è¼‰å…¥èªæ„æ¨¡å‹ (ç¬¬ä¸€æ¬¡åŸ·è¡Œæœƒéœ€è¦è¼ƒé•·æ™‚é–“)...")
    model = SentenceTransformer('distiluse-base-multilingual-cased-v1')
    logger.info("âœ… èªæ„æ¨¡å‹è¼‰å…¥æˆåŠŸã€‚")

    # 3. å°‡æ‰€æœ‰ç«™åè½‰æ›ç‚ºå‘é‡
    logger.info("â³ æ­£åœ¨å°‡æ‰€æœ‰ç«™åç·¨ç¢¼ç‚ºå‘é‡...")
    station_embeddings = model.encode(station_names, convert_to_tensor=False, show_progress_bar=True)
    
    # ç¢ºä¿è³‡æ–™æ ¼å¼ç‚º float32ï¼Œé€™æ˜¯ FAISS çš„è¦æ±‚
    station_embeddings = np.array(station_embeddings).astype('float32')
    logger.info(f"âœ… å‘é‡ç·¨ç¢¼å®Œæˆï¼Œå‘é‡ç¶­åº¦: {station_embeddings.shape}")

    # 4. å»ºç«‹ FAISS ç´¢å¼•
    embedding_dimension = station_embeddings.shape[1]
    index = faiss.IndexFlatL2(embedding_dimension) # ä½¿ç”¨ L2 è·é›¢ä½œç‚ºç›¸ä¼¼åº¦åº¦é‡
    index.add(station_embeddings)
    logger.info(f"âœ… FAISS ç´¢å¼•å»ºç«‹å®Œæˆï¼Œå…±ç´¢å¼• {index.ntotal} å€‹å‘é‡ã€‚")

    # 5. å„²å­˜ç´¢å¼•å’Œå°æ‡‰çš„ç«™ååˆ—è¡¨
    #    æˆ‘å€‘éœ€è¦åŒæ™‚å„²å­˜ç´¢å¼•å’Œç«™ååˆ—è¡¨ï¼Œæ‰èƒ½åœ¨æœå°‹å¾ŒçŸ¥é“æ‰¾åˆ°çš„æ˜¯å“ªå€‹ç«™å
    faiss_index_path = os.path.join(config.DATA_DIR, 'station_vector.index')
    names_path = os.path.join(config.DATA_DIR, 'station_names.json')

    faiss.write_index(index, faiss_index_path)
    with open(names_path, 'w', encoding='utf-8') as f:
        json.dump(station_names, f, ensure_ascii=False, indent=2)

    logger.info(f"--- ğŸ‰ æˆåŠŸï¼å‘é‡ç´¢å¼•å·²å„²å­˜è‡³ {faiss_index_path} ---")
    logger.info(f"--- ğŸ‰ æˆåŠŸï¼ç«™ååˆ—è¡¨å·²å„²å­˜è‡³ {names_path} ---")

if __name__ == "__main__":
    build_and_save_index()