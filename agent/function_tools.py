"""
agent/function_tools.py
~~~~~~~~~~~~~~~~~~~~~~~
æ‰€æœ‰å¯è¢« LLM Agent å‘¼å«çš„å·¥å…·å‡½å¼ã€‚
"""

from pathlib import Path
import json
import logging
from dotenv import load_dotenv
from langchain_core.tools import tool
from services import service_registry
import config, re

from utils.station_name_normalizer import normalize_station_name
from services.lost_item_search_service import lost_item_search_service
from datetime import datetime, timedelta
from utils.exceptions import StationNotFoundError, RouteNotFoundError

# ---------------------------------------------------------------------
# åŸºæœ¬è¨­å®š
# ---------------------------------------------------------------------
logger = logging.getLogger(__name__)

BASE_DIR = Path(__file__).resolve().parents[1]
load_dotenv(BASE_DIR / ".env")  # è‹¥å…¥å£æª”å·²è¼‰å…¥ .envï¼Œå¯æ‹¿æ‰

# ---------------------------------------------------------------------
# å¸¸ç”¨å–®ä¾‹æœå‹™
# ---------------------------------------------------------------------

metro_soap_api     = service_registry.get_soap_api()
routing_manager    = service_registry.get_routing_manager()
fare_service       = service_registry.get_fare_service()
station_manager    = service_registry.get_station_manager()
local_data_manager = service_registry.get_local_data_manager()
tdx_api            = service_registry.get_tdx_api()
# æ–°å¢ï¼šID è½‰æ›æœå‹™
id_converter       = service_registry.id_converter_service

# ---------------------------------------------------------------------
# 1. è·¯å¾‘è¦åŠƒ
# ---------------------------------------------------------------------#
@tool
def plan_route(start_station_name: str, end_station_name: str) -> str:
    """
    ã€è·¯å¾‘è¦åŠƒå°ˆå®¶ã€‘
    æ¥æ”¶èµ·é»å’Œçµ‚é»ç«™åï¼Œè¦åŠƒè·¯ç·šä¸¦æä¾›å…©ç¨®è³‡è¨Šï¼š
    1. è©³ç´°ã€äººæ€§åŒ–çš„æ­ä¹˜æ–¹å‘æŒ‡å¼•ã€‚
    2. å®˜æ–¹APIæä¾›çš„ã€åŒ…å«æ‰€æœ‰åœé ç«™çš„å®Œæ•´è·¯å¾‘åˆ—è¡¨ã€‚
    """
    logger.info(f"ğŸš€ [è·¯å¾‘è¦åŠƒ] é–‹å§‹è¦åŠƒè·¯å¾‘ï¼šå¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€ã€‚")

    # 1. é©—è­‰ç«™å
    start_result = station_manager.get_station_ids(start_station_name)
    end_result = station_manager.get_station_ids(end_station_name)

    # ... (ç«™åé©—è­‰é‚è¼¯èˆ‡æ‚¨æä¾›çš„ç‰ˆæœ¬ç›¸åŒï¼Œæ­¤è™•ç‚ºç°¡åŒ–çœç•¥ï¼Œè«‹ä¿ç•™æ‚¨åŸæœ‰çš„é©—è­‰ç¢¼)
    if isinstance(start_result, dict) and 'suggestion' in start_result:
        return json.dumps({"error": "need_confirmation", **start_result}, ensure_ascii=False)
    if not start_result or not isinstance(start_result, list):
        return json.dumps({"error": f"æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°åç‚ºã€Œ{start_station_name}ã€çš„æ·é‹ç«™ã€‚"}, ensure_ascii=False)
    if isinstance(end_result, dict) and 'suggestion' in end_result:
        return json.dumps({"error": "need_confirmation", **end_result}, ensure_ascii=False)
    if not end_result or not isinstance(end_result, list):
        return json.dumps({"error": f"æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°åç‚ºã€Œ{end_station_name}ã€çš„æ·é‹ç«™ã€‚"}, ensure_ascii=False)

    start_sid = id_converter.tdx_to_sid(start_result[0])
    end_sid = id_converter.tdx_to_sid(end_result[0])

    # 2. ä¸»è¦é‚è¼¯ï¼šå„ªå…ˆä½¿ç”¨å®˜æ–¹API
    if start_sid and end_sid:
        logger.info(f"ğŸ“ å˜—è©¦å‘¼å«åŒ—æ·å®˜æ–¹ SOAP API (SID: {start_sid} -> {end_sid})...")
        try:
            api_raw = metro_soap_api.get_recommended_route(start_sid, end_sid)
            
            if api_raw and isinstance(api_raw.get("path"), list) and len(api_raw["path"]) > 1:
                logger.info("âœ… æˆåŠŸå¾å®˜æ–¹ API ç²å–å»ºè­°è·¯ç·šï¼Œé–‹å§‹é€²è¡Œé›™é‡è·¯å¾‘è™•ç†...")
                
                # --- âœ¨ æ ¸å¿ƒæ”¹å‹• âœ¨ ---
                # 2.1 ç²å–åŸå§‹çš„å®Œæ•´è·¯å¾‘åˆ—è¡¨
                full_path_list = api_raw["path"]
                
                # 2.2 ç”¢ç”Ÿäººæ€§åŒ–çš„æ­ä¹˜æŒ‡å¼•
                detailed_directions = routing_manager.generate_directions_from_path(full_path_list)
                
                # 2.3 çµ„åˆåŒ…å«å…©ç¨®è³‡è¨Šçš„æœ€çµ‚è¨Šæ¯
                message = (
                    f"å¥½çš„ï¼Œå¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€çš„å»ºè­°è·¯ç·šå¦‚ä¸‹ï¼Œé ä¼°æ™‚é–“ç´„ {api_raw['time_min']} åˆ†é˜ï¼š\n\n"
                    f"**æ­ä¹˜æŒ‡å¼•ï¼š**\n" +
                    "\n".join(f"â¡ï¸ {step}" for step in detailed_directions) +
                    f"\n\n**è¡Œç¶“è»Šç«™ï¼š**\n" +
                    f"{' â†’ '.join(full_path_list)}"
                )
                
                # 2.4 å›å‚³åŒ…å«æ‰€æœ‰è³‡è¨Šçš„ JSON
                return json.dumps({
                    "source": "official_api_enhanced",
                    "time_min": api_raw["time_min"],
                    "directions": detailed_directions, # äººæ€§åŒ–æŒ‡å¼•
                    "full_path": full_path_list,       # åŸå§‹åœé ç«™
                    "message": message
                }, ensure_ascii=False)

        except Exception as e:
            logger.error(f"èª¿ç”¨å®˜æ–¹ SOAP API æˆ–äººæ€§åŒ–è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
    
    # 3. å‚™ç”¨æ–¹æ¡ˆ (ä¿æŒä¸è®Šï¼Œå®ƒæœ¬èº«å°±æœƒå›å‚³è©³ç´°è³‡è¨Š)
    logger.warning("SOAP API ç„¡æ³•ä½¿ç”¨æˆ–å‘¼å«å¤±æ•—ï¼Œå•Ÿå‹•å‚™ç”¨æ–¹æ¡ˆï¼šæœ¬åœ°è·¯ç¶²åœ–æ¼”ç®—æ³•ã€‚")
    try:
        fallback = routing_manager.find_shortest_path(start_station_name, end_station_name)
        if "path_details" in fallback:
            logger.info("âœ… æˆåŠŸé€éæœ¬åœ°æ¼”ç®—æ³•æ‰¾åˆ°å‚™ç”¨è·¯å¾‘ã€‚")
            fallback["message"] = "ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰" + fallback["message"]
            return json.dumps({"source": "local_fallback", **fallback}, ensure_ascii=False)
    except Exception as e:
        logger.error(f"æœ¬åœ°è·¯ç¶²è¦åŠƒæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}", exc_info=True)

    # 4. æœ€çµ‚å¤±æ•—
    logger.error(f"âŒ ç„¡æ³•è¦åŠƒè·¯å¾‘ï¼šå¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€ï¼Œæ‰€æœ‰æ–¹æ³•å‡å¤±æ•—ã€‚")
    return json.dumps({"error": f"éå¸¸æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è¦åŠƒå¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€çš„è·¯ç·šã€‚"}, ensure_ascii=False)
# ---------------------------------------------------------------------
# 2. ç¥¨åƒ¹æŸ¥è©¢
# ---------------------------------------------------------------------
@tool
def get_mrt_fare(start_station_name: str, end_station_name: str) -> str:
    """ã€ç¥¨åƒ¹æŸ¥è©¢å°ˆå®¶ã€‘å›å‚³å…¨ç¥¨èˆ‡å…’ç«¥ç¥¨åƒ¹æ ¼ï¼Œä¸å«è·¯å¾‘è¦åŠƒã€‚"""
    logger.info(f"[ç¥¨åƒ¹] {start_station_name} â†’ {end_station_name}")
    try:
        fare = fare_service.get_fare(start_station_name, end_station_name)
        return json.dumps({
            "start_station": start_station_name,
            "end_station":   end_station_name,
            "full_fare":     fare.get("full_fare", "æœªçŸ¥"),
            "child_fare":    fare.get("child_fare", "æœªçŸ¥"),
            "message": (
                f"å¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€çš„"
                f"å…¨ç¥¨ NT${fare.get('full_fare', 'æœªçŸ¥')}ï¼Œ"
                f"å…’ç«¥ç¥¨ NT${fare.get('child_fare', 'æœªçŸ¥')}ã€‚"
            )
        }, ensure_ascii=False)
    except StationNotFoundError as e:
        return json.dumps({"error": str(e)}, ensure_ascii=False)
    except Exception as e:
        logger.exception("ç¥¨åƒ¹æŸ¥è©¢å¤±æ•—")
        return json.dumps({"error": f"æŸ¥è©¢ç¥¨åƒ¹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 3. é¦–æœ«ç­è»Š
# ---------------------------------------------------------------------
@tool
def get_first_last_train_time(station_name: str) -> str:
    """ã€é¦–æœ«ç­è»Šå°ˆå®¶ã€‘æŸ¥è©¢æŒ‡å®šç«™é»å„æ–¹å‘é¦–/æœ«ç­æ™‚é–“ã€‚"""
    logger.info(f"[é¦–æœ«ç­è»Š] {station_name}")
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    timetable = tdx_api.get_first_last_timetable(station_ids[0])
    if not timetable:
        return json.dumps({"error": f"æŸ¥ç„¡ã€Œ{station_name}ã€é¦–æœ«ç­è»Šè³‡è¨Š"}, ensure_ascii=False)

    rows = [
        {"direction": t.get("TripHeadSign", "æœªçŸ¥æ–¹å‘"),
         "first":     t.get("FirstTrainTime", "N/A"),
         "last":      t.get("LastTrainTime", "N/A")}
        for t in timetable
    ]
    msg_lines = [f"ã€Œ{station_name}ã€é¦–æœ«ç­è»Šï¼š"]
    for r in rows:
        msg_lines.append(f"å¾€ {r['direction']} â†’ é¦–ç­ {r['first']}ï¼Œæœ«ç­ {r['last']}")

    return json.dumps({"station": station_name, "timetable": rows,
                       "message": "\n".join(msg_lines)}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 4. å‡ºå£è³‡è¨Š
# ---------------------------------------------------------------------
@tool
def get_station_exit_info(station_name: str) -> str:
    """ã€è»Šç«™å‡ºå£å°ˆå®¶ã€‘åˆ—å‡ºæ‰€æœ‰å‡ºå£ç·¨è™Ÿèˆ‡æè¿°ã€‚"""
    logger.info(f"[å‡ºå£] {station_name}")
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    exit_map = local_data_manager.exits
    exits: list[str] = []
    for sid in station_ids:
        exits.extend(
            f"å‡ºå£ {e.get('ExitNo', 'N/A')}: {e.get('Description', 'ç„¡æè¿°')}"
            for e in exit_map.get(sid, [])
        )

    if not exits:
        return json.dumps({"error": f"æŸ¥ç„¡ã€Œ{station_name}ã€å‡ºå£è³‡è¨Š"}, ensure_ascii=False)

    if all(x.endswith(": ç„¡æè¿°") for x in exits):
        msg = (f"ã€Œ{station_name}ã€å…±æœ‰ {len(exits)} å€‹å‡ºå…¥å£ï¼Œ"
               "ä½†æš«ç„¡è©³ç´°æè¿°ã€‚")
    else:
        msg = f"ã€Œ{station_name}ã€å‡ºå£è³‡è¨Šï¼š\n" + "\n".join(exits)

    return json.dumps({"station": station_name, "exits": exits,
                       "message": msg}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 5. è»Šç«™è¨­æ–½
# ---------------------------------------------------------------------
@tool
def get_station_facilities(station_name: str) -> str:
    """ã€è»Šç«™è¨­æ–½å°ˆå®¶ã€‘åˆ—å‡ºç«™å…§è¨­æ–½èˆ‡æè¿°ã€‚"""
    # 1. è¨˜éŒ„ Logï¼Œæ–¹ä¾¿æˆ‘å€‘åœ¨å¾Œå°çœ‹åˆ° AI ä½•æ™‚å‘¼å«äº†é€™å€‹å·¥å…·
    logger.info(f"[è¨­æ–½] {station_name}")

    # 2. å‘¼å« StationManagerï¼Œå°‡ä½¿ç”¨è€…å£èªåŒ–çš„ç«™åï¼ˆå¦‚ "åŒ—è»Š"ï¼‰
    #    è½‰æ›æˆæ¨™æº–çš„è»Šç«™ ID åˆ—è¡¨ï¼ˆå¦‚ ["BL12", "R10"]ï¼‰
    #    å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°±ç›´æ¥å›å‚³éŒ¯èª¤è¨Šæ¯ã€‚
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    # 3. è®€å–æˆ‘å€‘å»ºç«‹å¥½çš„è¨­æ–½è³‡æ–™åº« (mrt_station_facilities.json)
    #    ä¸¦æ ¹æ“šä¸Šä¸€æ­¥æ‰¾åˆ°çš„è»Šç«™ IDï¼ŒæŠŠå°æ‡‰çš„è©³ç´°è¨­æ–½è³‡è¨Šæ’ˆå‡ºä¾†ã€‚
    facilities = [
        local_data_manager.facilities.get(sid)
        for sid in station_ids
        if sid in local_data_manager.facilities
    ]
    # ç§»é™¤å¯èƒ½çš„ç©ºå€¼
    facilities = [f for f in facilities if f]

    # 4. å¦‚æœåœ¨è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ä»»ä½•è³‡è¨Šï¼Œå›å‚³æŸ¥ç„¡è³‡æ–™çš„éŒ¯èª¤ã€‚
    if not facilities:
        return json.dumps({"error": f"æŸ¥ç„¡ã€Œ{station_name}ã€è¨­æ–½è³‡è¨Š"}, ensure_ascii=False)

    # 5. å°‡æ‰¾åˆ°çš„è¨­æ–½è³‡è¨Šï¼ˆå¯èƒ½æœ‰å¤šç­†ï¼Œé‡å°è½‰ä¹˜ç«™ï¼‰åˆä½µæˆä¸€å€‹å­—ä¸²
    #    ä¸¦å»ºç«‹ä¸€å€‹å‹å–„çš„å›è¦†è¨Šæ¯ã€‚
    desc = "\n".join(list(set(facilities))) # ä½¿ç”¨ set é¿å…è½‰ä¹˜ç«™è³‡è¨Šé‡è¤‡
    msg = f"ã€Œ{station_name}ã€ç«™çš„è¨­æ–½è³‡è¨Šå¦‚ä¸‹ï¼š\n{desc}"

    # 6. å°‡æœ€çµ‚çµæœåŒ…è£æˆ JSON æ ¼å¼å›å‚³çµ¦ AI Agent
    return json.dumps({
        "station": station_name, 
        "facilities_info": desc,
        "message": msg
    }, ensure_ascii=False)

# ---------------------------------------------------------------------
# 6. éºå¤±ç‰©æ™ºæ…§æœå°‹ (æœ€çµ‚ç‰ˆ)
# ---------------------------------------------------------------------
@tool
def search_lost_and_found(
    item_description: str | None = None, 
    station_name: str | None = None,
    date_str: str | None = None
) -> str:
    """
    ã€éºå¤±ç‰©æ™ºæ…§æœå°‹å°ˆå®¶ã€‘
    æ ¹æ“šç‰©å“çš„æ¨¡ç³Šæè¿°ã€å¯èƒ½çš„åœ°é»å’Œæ—¥æœŸï¼ˆä¾‹å¦‚'æ˜¨å¤©'æˆ–'2025/08/02'ï¼‰ä¾†æœå°‹éºå¤±ç‰©ã€‚
    """
    logger.info(f"[æ™ºæ…§éºå¤±ç‰©æœå°‹] æ­£åœ¨æœå°‹: ç‰©å“='{item_description}', è»Šç«™='{station_name}', æ—¥æœŸ='{date_str}'")
    
    if not item_description and not station_name:
        return json.dumps({"error": "ç¼ºå°‘æœå°‹æ¢ä»¶", "message": "è«‹è‡³å°‘å‘Šè¨´æˆ‘ç‰©å“çš„æè¿°æˆ–å¯èƒ½çš„è»Šç«™å–”ï¼"}, ensure_ascii=False)

    # --- ã€âœ¨æ ¸å¿ƒæ“´å……âœ¨ã€‘å»ºç«‹ä¸€å€‹è¶…ç´šè±å¯Œçš„ã€Œç‰©å“åˆ¥ååœ°åœ–ã€ ---
    item_alias_map = {
        # ===== é›»å­ç¥¨è­‰é¡ =====
        "æ‚ éŠå¡": "é›»å­ç¥¨è­‰", "ä¸€å¡é€š": "é›»å­ç¥¨è­‰", "icash": "é›»å­ç¥¨è­‰",
        "æ„›é‡‘å¡": "é›»å­ç¥¨è­‰", "icå¡": "é›»å­ç¥¨è­‰", "å­¸ç”Ÿå¡": "é›»å­ç¥¨è­‰",
        "æ•¬è€å¡": "é›»å­ç¥¨è­‰", "æ„›å¿ƒå¡": "é›»å­ç¥¨è­‰",

        # ===== 3C / é›»å­ç”¢å“é¡ =====
        "æ‰‹æ©Ÿ": "è¡Œå‹•é›»è©±", "iphone": "è¡Œå‹•é›»è©±",
        "airpods": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)", "è—èŠ½è€³æ©Ÿ": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)", "ç„¡ç·šè€³æ©Ÿ": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)",
        "è€³æ©Ÿ": "ä»–é¡(è€³æ©Ÿ",  # ä½¿ç”¨ä¸å®Œæ•´çš„è©ï¼Œä»¥åŒ¹é… "è€³æ©Ÿ)" å’Œ "è€³æ©Ÿ("
        "airpods": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)",
        "airpods pro": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)",
        "å……é›»ç·š": "ä»–é¡(å……é›»(å‚³è¼¸)ç·š)", "å¿«å……ç·š": "ä»–é¡(å……é›»(å‚³è¼¸)ç·š)", "å‚³è¼¸ç·š": "ä»–é¡(å……é›»(å‚³è¼¸)ç·š)",
        "å……é›»å™¨": "ä»–é¡(å……é›»å™¨)", "è±†è…é ­": "ä»–é¡(å……é›»å™¨)",
        "è¡Œå‹•é›»æº": "ä»–é¡(è¡Œå‹•é›»æº)", "å……é›»å¯¶": "ä»–é¡(è¡Œå‹•é›»æº)",
        "é›»å­è¸": "ä»–é¡(é›»å­è¸)",
        "ç›¸æ©Ÿ": "ç…§ç›¸æ©Ÿ",

        # ===== è­‰ä»¶ / å¡ç‰‡é¡ =====
        "èº«åˆ†è­‰": "è­‰ä»¶", "å¥ä¿å¡": "è­‰ä»¶", "é§•ç…§": "è­‰ä»¶", "å­¸ç”Ÿè­‰": "è­‰ä»¶",
        "ä¿¡ç”¨å¡": "ä¿¡ç”¨å¡", "é‡‘èå¡": "é‡‘èå¡", "ææ¬¾å¡": "é‡‘èå¡",
        "å¡å¤¾": "è»Šç¥¨å¤¾", "ç¥¨å¡å¤¾": "è»Šç¥¨å¤¾",

        # ===== é›¨å…·é¡ =====
        "é›¨å‚˜": "å‚˜", "é™½å‚˜": "å‚˜",
        "æŠ˜ç–Šå‚˜": "æ‘ºå‚˜",
        "é•·æŸ„å‚˜": "é•·å‚˜",

        # ===== åŒ…åŒ… / è¢‹å­é¡ =====
        "éŒ¢åŒ…": "çš®å¤¾",
        "é›¶éŒ¢è¢‹": "é›¶éŒ¢åŒ…",
        "æè¢‹": "æ‰‹æè¢‹", "è³¼ç‰©è¢‹": "æ‰‹æè¢‹",
        "å¾ŒèƒŒåŒ…": "èƒŒåŒ…", "æ›¸åŒ…": "èƒŒåŒ…",
        "å¡‘è† è¢‹": "å¡‘è† è¢‹",
        "ç´™è¢‹": "ç´™è¢‹",

        # ===== è¡£ç‰© / é£¾å“é¡ =====
        "è¡£æœ": "è¡£ç‰©", "å¤–å¥—": "è¡£ç‰©",
        "å¸½å­": "å¸½å­",
        "æˆ’æŒ‡": "æˆ’æŒ‡", "é¦–é£¾": "é¦–é£¾", "é …éŠ": "é¦–é£¾", "æ‰‹éŠ": "é¦–é£¾", "è€³ç’°": "è€³ç’°",
        "çœ¼é¡": "çœ¼é¡", "å¤ªé™½çœ¼é¡": "çœ¼é¡",
        "æ‰‹éŒ¶": "æ‰‹éŒ¶",

        # ===== å…¶ä»–å¸¸è¦‹ã€Œä»–é¡ã€ç‰©å“ =====
        "ç­†": "ä»–é¡(ç­†)", "åŸå­ç­†": "ä»–é¡(ç­†)",
        "æ‰‹å¸•": "ä»–é¡(æ‰‹å¸•)",
        "æŸå£è¢‹": "ä»–é¡(æŸå£è¢‹)",
        "åŠé£¾": "ä»–é¡(åŠé£¾)", "é‘°åŒ™åœˆ": "ä»–é¡(åŠé£¾)",

        # ===== å…¶ä»–å¸¸è¦‹ç‰©å“ =====
        "é‘°åŒ™": "é‘°åŒ™",
        "æ°´å£º": "æ°´å£º", "ä¿æº«ç“¶": "ä¿æº«ç“¶",
        "å¨ƒå¨ƒ": "ç©å¶", "å…¬ä»”": "ç©å¶",
    }
    # ----------------------------------------------------

    # --- æ­¥é©Ÿ 1: è™•ç†æ—¥æœŸ ---
    search_date = None
    if date_str:
        try:
            if "æ˜¨å¤©" in date_str:
                search_date = (datetime.now() - timedelta(days=1)).strftime('%Y/%m/%d')
            elif "ä»Šå¤©" in date_str:
                search_date = datetime.now().strftime('%Y/%m/%d')
            else:
                search_date = datetime.strptime(date_str, '%Y/%m/%d').strftime('%Y/%m/%d')
            logger.info(f"æ—¥æœŸæ¢ä»¶è§£ææˆåŠŸ: {search_date}")
        except ValueError:
            logger.warning(f"ç„¡æ³•è§£ææ—¥æœŸå­—ä¸²: '{date_str}'ï¼Œå°‡å¿½ç•¥æ—¥æœŸæ¢ä»¶ã€‚")
            pass

    # --- æ­¥é©Ÿ 2: è™•ç†åœ°é» (ç«™å -> ç«™å + è·¯ç·šå) ---
    search_locations = set()
    if station_name:
        norm_station_name = station_name.replace("ç«™", "").replace("é§…", "")
        search_locations.add(norm_station_name)
        
        station_ids = station_manager.get_station_ids(station_name)
        if isinstance(station_ids, list) and station_ids:
            line_prefix_match = re.match(r"([A-Z]+)", station_ids[0])
            if line_prefix_match:
                line_prefix = line_prefix_match.group(1)
                line_map = {'BL': 'æ¿å—ç·š', 'BR': 'æ–‡æ¹–ç·š', 'R': 'æ·¡æ°´ä¿¡ç¾©ç·š', 'G': 'æ¾å±±æ–°åº—ç·š', 'O': 'ä¸­å’Œæ–°è˜†ç·š', 'Y': 'ç’°ç‹€ç·š'}
                line_name = line_map.get(line_prefix)
                if line_name:
                    search_locations.add(line_name)
        logger.info(f"åœ°é»æ¢ä»¶æ“´å±•ç‚º: {search_locations}")

    # --- æ­¥é©Ÿ 3: è™•ç†ç‰©å“ (ç²¾æº–åˆ¥å -> èªæ„æœå°‹) ---
    search_item_terms = set()
    if item_description:
        # 1. å„ªå…ˆä½¿ç”¨ã€Œç²¾æº–åˆ¥åã€é€²è¡Œè½‰æ›
        norm_item_desc = item_description.lower()
        if norm_item_desc in item_alias_map:
            official_item_name = item_alias_map[norm_item_desc]
            search_item_terms.add(official_item_name.lower())
            logger.info(f"ç‰©å“ '{norm_item_desc}' é€éåˆ¥åç²¾æº–åŒ¹é…åˆ° '{official_item_name}'")
        
        # 2. æ¥è‘—ï¼Œä½¿ç”¨ã€Œå‘é‡æœå°‹ã€ä¾†å°‹æ‰¾å…¶ä»–èªæ„ç›¸ä¼¼çš„è©
        found_names = lost_item_search_service.find_similar_items(item_description, top_k=3, threshold=0.6)
        if found_names:
            search_item_terms.update(name.lower() for name in found_names)
            
        # 3. ç„¡è«–å¦‚ä½•ï¼Œéƒ½å°‡ä½¿ç”¨è€…åŸå§‹çš„æè¿°ä¹ŸåŠ å…¥æœå°‹ç›®æ¨™
        search_item_terms.add(norm_item_desc)
        logger.info(f"ç‰©å“æ¢ä»¶æ“´å±•ç‚º: {search_item_terms}")

    # --- æ­¥é©Ÿ 4: è¼‰å…¥è³‡æ–™ä¸¦åŸ·è¡Œæœ€çµ‚ç¯©é¸ ---
    try:
        with open(config.LOST_AND_FOUND_DATA_PATH, 'r', encoding='utf-8') as f:
            all_items = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        logger.error(f"éºå¤±ç‰©è³‡æ–™åº«æª”æ¡ˆéºå¤±æˆ–ææ¯€: {config.LOST_AND_FOUND_DATA_PATH}")
        return json.dumps({"error": "è³‡æ–™åº«éŒ¯èª¤", "message": "æŠ±æ­‰ï¼Œéºå¤±ç‰©è³‡æ–™åº«å¥½åƒä¸è¦‹äº†ã€‚"}, ensure_ascii=False)

    filtered_items = all_items
    if search_date:
        filtered_items = [item for item in filtered_items if item.get('col_Date') == search_date]
    if search_locations:
        filtered_items = [item for item in filtered_items if any(loc.lower() in item.get('col_TRTCStation', '').lower() for loc in search_locations)]
    if search_item_terms:
        filtered_items = [item for item in filtered_items if any(term in item.get('col_LoseName', '').lower() for term in search_item_terms)]

    # --- æ­¥é©Ÿ 5: æ ¼å¼åŒ–ä¸¦å›å‚³çµæœ ---
    top_results = filtered_items[:10]
    
    if not top_results:
        return json.dumps({"count": 0, "message": "å¾ˆæŠ±æ­‰ï¼Œåœ¨è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„éºå¤±ç‰©ã€‚"}, ensure_ascii=False)

    formatted_results = [
        {"æ‹¾ç²æ—¥æœŸ": item.get("col_Date"), "ç‰©å“åç¨±": item.get("col_LoseName"), "æ‹¾ç²è»Šç«™": item.get("col_TRTCStation"), "ä¿ç®¡å–®ä½": item.get("col_NowPlace")}
        for item in top_results
    ]
    
    return json.dumps({
        "count": len(top_results),
        "message": f"å¥½çš„ï¼Œå¹«æ‚¨åœ¨è³‡æ–™åº«ä¸­æ‰¾åˆ°äº† {len(top_results)} ç­†æœ€ç›¸é—œçš„éºå¤±ç‰©è³‡è¨Šï¼š",
        "results": formatted_results
    }, ensure_ascii=False, indent=2)


# ---------------------------------------------------------------------
# 7. æ·é‹ç¾é£Ÿæœå°‹ (æ–°åŠŸèƒ½)
# ---------------------------------------------------------------------
@tool
def search_mrt_food(station_name: str, source_keyword: str | None = None) -> str:
    """
    ã€æ·é‹ç¾é£Ÿå®¶ã€‘
    æ ¹æ“šä½¿ç”¨è€…æä¾›çš„æ·é‹ç«™åï¼ŒæŸ¥è©¢è©²ç«™é™„è¿‘æ¨è–¦çš„ç¾é£Ÿã€‚
    å¯é¸æ“‡æ€§åœ°æ ¹æ“šä¾†æºé—œéµå­—(ä¾‹å¦‚ 'ç±³å…¶æ—', 'é»ƒä»å‹³', '500ç¢—')é€²è¡Œç¯©é¸ã€‚
    """
    # âœ¨ æ–°å¢ï¼šè®“æ—¥èªŒä¹Ÿè¨˜éŒ„ä¸‹ä¾†æºé—œéµå­—ï¼Œæ–¹ä¾¿é™¤éŒ¯
    logger.info(f"[ç¾é£Ÿæœå°‹] æ­£åœ¨æœå°‹ã€Œ{station_name}ã€ï¼Œä¾†æºé—œéµå­—: '{source_keyword}'")

    # 1. é©—è­‰ä¸¦å–å¾—æ¨™æº–åŒ–çš„ç«™å (é‚è¼¯ä¸è®Š)
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    # 2. è¼‰å…¥ç¾é£Ÿåœ°åœ–è³‡æ–™ (é‚è¼¯ä¸è®Š)
    food_map = local_data_manager.food_map
    if not food_map:
        return json.dumps({"error": "ç¾é£Ÿåœ°åœ–è³‡æ–™å°šæœªè¼‰å…¥ã€‚"}, ensure_ascii=False)
        
    # 3. å…ˆæ‰¾å‡ºè©²ç«™é»çš„ã€Œæ‰€æœ‰ã€é¤å»³ (é‚è¼¯ä¸è®Š)
    norm_station_name = normalize_station_name(station_name)
    all_restaurants_at_station = []
    for entry in food_map:
        if normalize_station_name(entry.get("station")) == norm_station_name:
            all_restaurants_at_station = entry.get("restaurants", [])
            break
    
    # âœ¨âœ¨âœ¨ã€æ ¸å¿ƒä¿®æ”¹ã€‘å°‡ç¯©é¸é‚è¼¯æ”¾åœ¨é€™è£¡ âœ¨âœ¨âœ¨
    # æª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦æä¾›äº† `source_keyword`ï¼Œä¸¦ä¸”æˆ‘å€‘ç¢ºå¯¦æ‰¾åˆ°äº†é¤å»³åˆ—è¡¨
    if source_keyword and all_restaurants_at_station:
        logger.info(f"--- åµæ¸¬åˆ°é—œéµå­— '{source_keyword}'ï¼Œé–‹å§‹é€²è¡Œç¯©é¸...")
        
        filtered_restaurants = []
        # éæ­·æ¯ä¸€å®¶é¤å»³
        for restaurant in all_restaurants_at_station:
            # å–å¾—é¤å»³çš„ source æ¬„ä½ï¼Œå¯èƒ½æ˜¯ä¸€å€‹å­—ä¸²ï¼Œä¹Ÿå¯èƒ½æ˜¯ä¸€å€‹åˆ—è¡¨
            source_info = restaurant.get("source", "")
            
            # ç‚ºäº†èƒ½çµ±ä¸€è™•ç†ï¼Œæˆ‘å€‘å°‡ source è½‰æˆä¸€å€‹ JSON å­—ä¸²ä¾†é€²è¡Œæ¯”å°
            # é€™æ¨£ç„¡è«–å®ƒæ˜¯ "ç±³å…¶æ—" é‚„æ˜¯ ["ç±³å…¶æ—", "500ç¢—"]ï¼Œéƒ½èƒ½è¢«æœå°‹åˆ°
            source_text_for_search = json.dumps(source_info, ensure_ascii=False).lower()
            
            # å¦‚æœé—œéµå­—å­˜åœ¨æ–¼ source çš„æ–‡å­—ä¸­ï¼Œå°±å°‡é€™å®¶é¤å»³åŠ å…¥ç¯©é¸çµæœ
            if source_keyword.lower() in source_text_for_search:
                filtered_restaurants.append(restaurant)
        
        # ç”¨ç¯©é¸å¾Œçš„çµæœï¼Œè¦†è“‹æ‰åŸæœ¬çš„é¤å»³åˆ—è¡¨
        found_restaurants = filtered_restaurants
        logger.info(f"--- ç¯©é¸å®Œç•¢ï¼Œæ‰¾åˆ° {len(found_restaurants)} ç­†ç›¸ç¬¦çš„çµæœã€‚")
    else:
        # å¦‚æœæ²’æœ‰æä¾›é—œéµå­—ï¼Œå°±ä½¿ç”¨å…¨éƒ¨çš„é¤å»³åˆ—è¡¨
        found_restaurants = all_restaurants_at_station

    # 4. æª¢æŸ¥æœ€çµ‚æ˜¯å¦æœ‰çµæœ (é‚è¼¯ä¸è®Š)
    if not found_restaurants:
        # å¦‚æœæ˜¯ç¯©é¸å¾Œæ²’æœ‰çµæœï¼Œå¯ä»¥çµ¦å‡ºæ›´ç²¾ç¢ºçš„æç¤º
        if source_keyword:
             message = f"å“å‘€ï¼Œåœ¨ã€Œ{station_name}ã€é™„è¿‘ï¼Œæˆ‘æ‰¾ä¸åˆ°ç¬¦åˆã€Œ{source_keyword}ã€é€™å€‹ä¾†æºçš„ç¾é£Ÿè³‡è¨Šè€¶ã€‚"
        else:
             message = f"å“å‘€ï¼Œæˆ‘ç›®å‰é‚„æ²’æœ‰æ”¶è—ã€Œ{station_name}ã€é™„è¿‘çš„ç¾é£Ÿè³‡è¨Šè€¶ã€‚"
        
        return json.dumps({
            "station": station_name,
            "count": 0,
            "message": message
        }, ensure_ascii=False)

    # 5. æ ¼å¼åŒ–ä¸¦å›å‚³æœ€çµ‚çµæœ (é‚è¼¯ä¸è®Š)
    return json.dumps({
        "station": station_name,
        "count": len(found_restaurants),
        "message": f"å¥½çš„ï¼Œå¹«æ‚¨æ‰¾åˆ°äº† {len(found_restaurants)} å®¶åœ¨ã€Œ{station_name}ã€é™„è¿‘çš„ç¾é£Ÿï¼š",
        "restaurants": found_restaurants
    }, ensure_ascii=False, indent=2)

@tool
def list_available_food_maps() -> str:
    """
    ã€ç¾é£Ÿåœ°åœ–ç›¤é»å°ˆå®¶ã€‘
    æƒæç¾é£Ÿè³‡æ–™åº«ï¼Œå›å‚³æ‰€æœ‰ä¸é‡è¤‡çš„ç¾é£Ÿåœ°åœ–ä¾†æºç¨®é¡ã€‚
    """
    logger.info("[ç›¤é»è³‡æº] æ­£åœ¨æƒæå¯ç”¨çš„ç¾é£Ÿåœ°åœ–ç¨®é¡...")
    
    food_map = local_data_manager.food_map
    if not food_map:
        return json.dumps({"error": "ç¾é£Ÿåœ°åœ–è³‡æ–™å°šæœªè¼‰å…¥ã€‚"}, ensure_ascii=False)

    unique_sources = set()
    for entry in food_map:
        for restaurant in entry.get("restaurants", []):
            source_info = restaurant.get("source")
            if not source_info:
                continue
            
            # è™•ç† source æ˜¯åˆ—è¡¨çš„æƒ…æ³ (ä¾‹å¦‚: ["ç±³å…¶æ—", "500ç¢—"])
            if isinstance(source_info, list):
                for s in source_info:
                    unique_sources.add(s)
            # è™•ç† source æ˜¯å–®ä¸€å­—ä¸²çš„æƒ…æ³
            elif isinstance(source_info, str):
                unique_sources.add(source_info)

    if not unique_sources:
        return json.dumps({"count": 0, "maps": []}, ensure_ascii=False)

    # ç‚ºäº†è®“åç¨±æ›´ç°¡æ½”ï¼Œå¯ä»¥åšä¸€äº›åŸºæœ¬æ¸…ç†
    # ä¾‹å¦‚ï¼Œå¾ "ã€Šå°ç£ç±³å…¶æ—æŒ‡å—2024ã€‹å¿…æ¯”ç™»æ¨ä»‹åœ°åœ–" ä¸­å–å‡º "å¿…æ¯”ç™»"
    cleaned_names = set()
    for s in unique_sources:
        if "å¿…æ¯”ç™»" in s:
            cleaned_names.add("ç±³å…¶æ—å¿…æ¯”ç™»æ¨è–¦")
        elif "ç±³å…¶æ—" in s:
            cleaned_names.add("ç±³å…¶æ—æ˜Ÿç´šé¤å»³")
        elif "é»ƒä»å‹³" in s:
            cleaned_names.add("é»ƒä»å‹³ç¾é£Ÿåœ°åœ–")
        elif "500ç¢—" in s:
            cleaned_names.add("500ç¢—å°åƒåœ°åœ–")
        elif "å¯µç‰©å‹å–„" in s:
            cleaned_names.add("å¯µç‰©å‹å–„é¤å»³")
        else:
            cleaned_names.add(s) # å¦‚æœæ²’æœ‰åŒ¹é…ï¼Œä¿ç•™åŸå

    map_list = sorted(list(cleaned_names))

    return json.dumps({
        "count": len(map_list),
        "maps": map_list,
        "message": f"æˆ‘é€™è£¡æœ‰ {len(map_list)} ç¨®ç¾é£Ÿåœ°åœ–å¯ä¾›åƒè€ƒï¼š{', '.join(map_list)}ã€‚"
    }, ensure_ascii=False, indent=2)

@tool
def get_metro_line_info(line_name: str) -> str:
    """
    ã€æ·é‹è·¯ç¶²å°ˆå®¶ã€‘
    ç•¶ä½¿ç”¨è€…è©¢å•é—œæ–¼ç‰¹å®šæ·é‹ã€Œè·¯ç·šã€çš„è³‡è¨Šæ™‚ä½¿ç”¨æ­¤å·¥å…·ã€‚
    ä¾‹å¦‚ï¼šã€Œæ–‡æ¹–ç·šçš„èµ·é»å’Œçµ‚é»æ˜¯å“ªè£¡ï¼Ÿã€ã€ã€Œæ¿å—ç·šæœ‰å“ªäº›è½‰ä¹˜ç«™ï¼Ÿã€
    å®ƒæœƒå›å‚³è©²è·¯ç·šçš„èµ·è¨–ç«™ã€æ‰€æœ‰è»Šç«™å’Œå¯è½‰ä¹˜çš„ç«™é»åˆ—è¡¨ã€‚
    """
    logger.info(f"ğŸ—ºï¸ [è·¯ç¶²æŸ¥è©¢] æ­£åœ¨æŸ¥è©¢è·¯ç·šè³‡è¨Šï¼š{line_name}")
    
    # æ¨™æº–åŒ–ä½¿ç”¨è€…å¯èƒ½è¼¸å…¥çš„ç°¡ç¨±
    normalized_map = {
        "æ£•": "æ–‡æ¹–ç·š", "æ–‡æ¹–": "æ–‡æ¹–ç·š", "br": "æ–‡æ¹–ç·š",
        "ç´…": "æ·¡æ°´ä¿¡ç¾©ç·š", "æ·¡æ°´ä¿¡ç¾©": "æ·¡æ°´ä¿¡ç¾©ç·š", "r": "æ·¡æ°´ä¿¡ç¾©ç·š",
        "ç¶ ": "æ¾å±±æ–°åº—ç·š", "æ¾å±±æ–°åº—": "æ¾å±±æ–°åº—ç·š", "g": "æ¾å±±æ–°åº—ç·š",
        "æ©˜": "ä¸­å’Œæ–°è˜†ç·š", "ä¸­å’Œæ–°è˜†": "ä¸­å’Œæ–°è˜†ç·š", "o": "ä¸­å’Œæ–°è˜†ç·š",
        "è—": "æ¿å—ç·š", "æ¿å—": "æ¿å—ç·š", "bl": "æ¿å—ç·š",
        "é»ƒ": "ç’°ç‹€ç·š", "ç’°ç‹€": "ç’°ç‹€ç·š", "y": "ç’°ç‹€ç·š",
    }
    
    # æŸ¥æ‰¾æœ€ç¬¦åˆçš„è·¯ç·šå…¨å
    best_match_name = line_name
    for key, value in normalized_map.items():
        if key in line_name.lower():
            best_match_name = value
            break
            
    line_details = routing_manager.get_line_details(best_match_name)
    
    return json.dumps(line_details, ensure_ascii=False, indent=2)

# âœ¨âœ¨âœ¨ START: æ–°å¢çš„å·¥å…· âœ¨âœ¨âœ¨
@tool
def list_all_metro_lines() -> str:
    """
    ã€æ·é‹è·¯ç·šç›¤é»å°ˆå®¶ã€‘
    ç•¶ä½¿ç”¨è€…è©¢å•ã€Œæœ‰å“ªäº›æ·é‹ç·šï¼Ÿã€æˆ–è¦æ±‚åˆ—å‡ºæ‰€æœ‰è·¯ç·šæ™‚ä½¿ç”¨æ­¤å·¥å…·ã€‚
    å®ƒæœƒå›å‚³ä¸€å€‹åŒ…å«æ‰€æœ‰æ·é‹ç·šçš„åç¨±ã€ä»£è™Ÿå’Œé¡è‰²çš„å®Œæ•´åˆ—è¡¨ã€‚
    """
    logger.info("ğŸ—ºï¸ [è·¯ç¶²æŸ¥è©¢] æ­£åœ¨åˆ—å‡ºæ‰€æœ‰æ·é‹è·¯ç·š...")
    all_lines = routing_manager.list_all_lines()
    return json.dumps(all_lines, ensure_ascii=False, indent=2)
# âœ¨âœ¨âœ¨ END: æ–°å¢çš„å·¥å…· âœ¨âœ¨âœ¨

@tool
def list_all_stations() -> str:
    """
    ã€æ·é‹è»Šç«™ç›¤é»å°ˆå®¶ã€‘
    ç•¶ä½¿ç”¨è€…è©¢å•ã€Œæœ‰å“ªäº›æ·é‹ç«™ï¼Ÿã€æˆ–è¦æ±‚åˆ—å‡ºæ‰€æœ‰è»Šç«™æ™‚ä½¿ç”¨æ­¤å·¥å…·ã€‚
    """
    logger.info("ğŸš‰ [è»Šç«™æŸ¥è©¢] æ­£åœ¨åˆ—å‡ºæ‰€æœ‰æ·é‹è»Šç«™...")
    station_names = station_manager.get_all_station_names()
    
    if not station_names:
        return json.dumps({"error": "ç„¡æ³•ç²å–è»Šç«™åˆ—è¡¨ã€‚"}, ensure_ascii=False)
        
    return json.dumps({
        "count": len(station_names),
        "stations": station_names,
        "message": f"å°åŒ—æ·é‹ç³»çµ±ç›®å‰å…±æœ‰ {len(station_names)} å€‹è»Šç«™ã€‚"
    }, ensure_ascii=False, indent=2)
# âœ¨âœ¨âœ¨ END: æ–°å¢çš„å·¥å…· âœ¨âœ¨âœ¨

@tool
def get_best_car_for_exit(station_name: str, direction: str, exit_number: int) -> str:
    """
    ã€æœ€ä½³è»Šå»‚æ¨è–¦å°ˆå®¶ã€‘
    ç•¶ä½¿ç”¨è€…åˆ°é”æŸå€‹æ·é‹ç«™ï¼Œä¸¦æƒ³çŸ¥é“å‰å¾€ç‰¹å®šå‡ºå£ï¼ˆä¾‹å¦‚3è™Ÿå‡ºå£ï¼‰æ‡‰è©²å¾å“ªå€‹è»Šå»‚ä¸‹è»Šæœ€å¿«æ™‚ï¼Œä½¿ç”¨æ­¤å·¥å…·ã€‚
    ä½ éœ€è¦æä¾›è»Šç«™åç¨±ã€åˆ—è»Šçš„è¡Œé§›æ–¹å‘ï¼ˆçµ‚é»ç«™åç¨±ï¼‰ï¼Œä»¥åŠä½¿ç”¨è€…æƒ³å»çš„å‡ºå£è™Ÿç¢¼ã€‚
    """
    logger.info(f" optimizing [æœ€ä½³è»Šå»‚æ¨è–¦] æ­£åœ¨ç‚ºã€Œ{station_name}ã€ç«™ï¼Œå¾€ã€Œ{direction}ã€æ–¹å‘ï¼ŒæŸ¥è©¢é è¿‘ã€Œ{exit_number}ã€è™Ÿå‡ºå£çš„è»Šå»‚ã€‚")

    # 1. è¼‰å…¥è»Šå»‚å‡ºå£å°æ‡‰è³‡æ–™
    car_exit_data = local_data_manager.car_exit_map
    if not car_exit_data:
        return json.dumps({"error": "è»Šå»‚å‡ºå£å°æ‡‰è³‡æ–™å°šæœªè¼‰å…¥ã€‚"}, ensure_ascii=False)

    # 2. æ¨™æº–åŒ–ç«™åä»¥ä¾¿æœå°‹
    norm_station = normalize_station_name(station_name)
    
    # 3. å°‹æ‰¾ç¬¦åˆçš„è»Šç«™ã€è·¯ç·šèˆ‡æ–¹å‘
    found_cars = []
    station_info = None
    for item in car_exit_data:
        if normalize_station_name(item.get("station")) == norm_station:
            station_info = item
            break
            
    if not station_info:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°ã€Œ{station_name}ã€çš„è»Šå»‚å‡ºå£è³‡æ–™ã€‚"}, ensure_ascii=False)

    # 4. å°‹æ‰¾æœ€åŒ¹é…çš„æ–¹å‘ (è™•ç† "å¾€å‹•ç‰©åœ’" vs "å‹•ç‰©åœ’" çš„æƒ…æ³)
    direction_data = None
    for dir_key, dir_value in station_info.get("Directions", {}).items():
        if direction in dir_key or dir_key in direction:
            direction_data = dir_value
            break
            
    if not direction_data:
         return json.dumps({"error": f"åœ¨ã€Œ{station_name}ã€ç«™æ‰¾ä¸åˆ°å¾€ã€Œ{direction}ã€æ–¹å‘çš„åˆ—è»Šè³‡è¨Šã€‚"}, ensure_ascii=False)

    # 5. éæ­·è»Šå»‚åˆ—è¡¨ï¼Œæ‰¾å‡ºåŒ…å«ç›®æ¨™å‡ºå£çš„è»Šå»‚
    for car_info in direction_data.get("list", []):
        if exit_number in car_info.get("exits", []):
            found_cars.append(str(car_info.get("car")))

    # 6. æ ¼å¼åŒ–å›å‚³è¨Šæ¯
    if not found_cars:
        message = f"å¾ˆæŠ±æ­‰ï¼Œåœ¨ã€Œ{station_name}ã€ç«™å¾€ã€Œ{direction}ã€æ–¹å‘çš„åˆ—è»Šï¼Œè³‡æ–™ä¸­æ²’æœ‰ç‰¹åˆ¥æ¨™ç¤ºé è¿‘ {exit_number} è™Ÿå‡ºå£çš„è»Šå»‚ã€‚å»ºè­°æ‚¨åœ¨æœˆå°ç•™æ„å‡ºå£æŒ‡ç¤ºåœ–ã€‚"
        return json.dumps({"station": station_name, "exit_number": exit_number, "found": False, "message": message}, ensure_ascii=False)
    
    car_str = "ã€".join(found_cars)
    message = f"å¥½çš„ï¼åœ¨ã€Œ{station_name}ã€ç«™ä¸‹è»Šå¾Œï¼Œè‹¥è¦å‰å¾€ {exit_number} è™Ÿå‡ºå£ï¼Œå»ºè­°æ‚¨æ­ä¹˜ç¬¬ **{car_str}** ç¯€è»Šå»‚æœƒæœ€å¿«æŠµé”ï¼"
    
    return json.dumps({
        "station": station_name,
        "direction": direction,
        "exit_number": exit_number,
        "recommended_cars": found_cars,
        "message": message
    }, ensure_ascii=False)

# ---------------------------------------------------------------------
# åŒ¯å‡ºå·¥å…·æ¸…å–®
# ---------------------------------------------------------------------
all_tools = [
    plan_route,
    get_mrt_fare,
    get_first_last_train_time,
    get_station_exit_info,
    get_station_facilities,
    search_lost_and_found,
    search_mrt_food,
    list_available_food_maps,
    get_metro_line_info,
    list_all_metro_lines,
    list_all_stations, 
    get_best_car_for_exit,
]
