"""
agent/function_tools.py
~~~~~~~~~~~~~~~~~~~~~~~
æ‰€æœ‰å¯è¢« LLM Agent å‘¼å«çš„å·¥å…·å‡½å¼ã€‚
"""

from pathlib import Path
import json
import logging
from dotenv import load_dotenv
from langchain_core.tools import tool
from services import service_registry
import config, re

from services.lost_item_search_service import lost_item_search_service
from datetime import datetime, timedelta
from utils.exceptions import StationNotFoundError, RouteNotFoundError

# ---------------------------------------------------------------------
# åŸºæœ¬è¨­å®š
# ---------------------------------------------------------------------
logger = logging.getLogger(__name__)

BASE_DIR = Path(__file__).resolve().parents[1]
load_dotenv(BASE_DIR / ".env")  # è‹¥å…¥å£æª”å·²è¼‰å…¥ .envï¼Œå¯æ‹¿æ‰

# ---------------------------------------------------------------------
# å¸¸ç”¨å–®ä¾‹æœå‹™
# ---------------------------------------------------------------------

metro_soap_api     = service_registry.get_soap_api()
routing_manager    = service_registry.get_routing_manager()
fare_service       = service_registry.get_fare_service()
station_manager    = service_registry.get_station_manager()
local_data_manager = service_registry.get_local_data_manager()
tdx_api            = service_registry.get_tdx_api()
# æ–°å¢ï¼šID è½‰æ›æœå‹™
id_converter       = service_registry.id_converter_service

# ---------------------------------------------------------------------
# 1. è·¯å¾‘è¦åŠƒ
# ---------------------------------------------------------------------


@tool
def plan_route(start_station_name: str, end_station_name: str) -> str:
    """
    ã€è·¯å¾‘è¦åŠƒå°ˆå®¶ã€‘
    æ¥æ”¶ç«™åï¼Œå¦‚æœç«™åæ¨¡ç³Šï¼Œæœƒè¿”å›ä¸€å€‹è«‹æ±‚ç¢ºèªçš„éŒ¯èª¤ã€‚
    """
    logger.info(f"ğŸš€ [è·¯å¾‘è¦åŠƒ] é–‹å§‹è¦åŠƒè·¯å¾‘ï¼šå¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€ã€‚")

    start_result = station_manager.get_station_ids(start_station_name)
    end_result = station_manager.get_station_ids(end_station_name)

    # æª¢æŸ¥èµ·é»
    if isinstance(start_result, dict) and 'suggestion' in start_result:
        return json.dumps({"error": "need_confirmation", **start_result}, ensure_ascii=False)
    if not start_result:
        return json.dumps({"error": f"æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°åç‚ºã€Œ{start_station_name}ã€çš„æ·é‹ç«™ã€‚"}, ensure_ascii=False)

    # æª¢æŸ¥çµ‚é»
    if isinstance(end_result, dict) and 'suggestion' in end_result:
        return json.dumps({"error": "need_confirmation", **end_result}, ensure_ascii=False)
    if not end_result:
        return json.dumps({"error": f"æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°åç‚ºã€Œ{end_station_name}ã€çš„æ·é‹ç«™ã€‚"}, ensure_ascii=False)

    # --- å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œç¹¼çºŒåŸæœ‰çš„IDè½‰æ›å’ŒAPIå‘¼å«æµç¨‹ ---
    start_tdx_id = start_result[0]
    end_tdx_id = end_result[0]
    logger.info(f"TDX ID è§£ææˆåŠŸ: start='{start_tdx_id}', end='{end_tdx_id}'")

    start_sid = id_converter.tdx_to_sid(start_tdx_id)
    end_sid = id_converter.tdx_to_sid(end_tdx_id)
    logger.info(f"ç´”æ•¸å­— SID è½‰æ›æˆåŠŸ: start='{start_sid}', end='{end_sid}'")

    # ... (å¾ŒçºŒçš„ try/except API å‘¼å«å’Œ fallback é‚è¼¯å®Œå…¨ä¸è®Š) ...
    if start_sid and end_sid:
        logger.info("ğŸ“ å˜—è©¦å‘¼å«åŒ—æ·å®˜æ–¹ SOAP API...")
        try:
            api_raw = metro_soap_api.get_recommended_route(start_sid, end_sid)
            if api_raw and api_raw.get("path"):
                logger.info(f"âœ… æˆåŠŸå¾å®˜æ–¹ API ç²å–å»ºè­°è·¯ç·šï¼Œè€—æ™‚ {api_raw.get('time_min', 'N/A')} åˆ†é˜ã€‚")
                msg = (
                    f"å®˜æ–¹å»ºè­°è·¯ç·šï¼š{start_station_name} â†’ {end_station_name}ï¼Œ"
                    f"ç´„ {api_raw['time_min']} åˆ†é˜ã€‚\n"
                    f"è·¯å¾‘ï¼š{' â†’ '.join(api_raw['path'])}"
                )
                if api_raw.get("transfers"):
                    msg += f"\nè½‰ä¹˜ç«™ï¼š{'ã€'.join(api_raw['transfers'])}"
                return json.dumps({
                    "source":   "official_api",
                    "route":    api_raw["path"],
                    "time_min": api_raw["time_min"],
                    "transfer": api_raw.get("transfers", []),
                    "message":  msg
                }, ensure_ascii=False)
        except Exception as e:
            logger.error(f"èª¿ç”¨å®˜æ–¹ SOAP API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)

    logger.warning("SOAP API ç„¡æ³•ä½¿ç”¨æˆ–å‘¼å«å¤±æ•—ï¼Œå•Ÿå‹•å‚™ç”¨æ–¹æ¡ˆï¼šæœ¬åœ°è·¯ç¶²åœ–æ¼”ç®—æ³•ã€‚")
    try:
        fallback = routing_manager.find_shortest_path(start_station_name, end_station_name)
        if "path_details" in fallback:
            logger.info("âœ… æˆåŠŸé€éæœ¬åœ°æ¼”ç®—æ³•æ‰¾åˆ°å‚™ç”¨è·¯å¾‘ã€‚")
            fallback["message"] = "ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰" + fallback["message"]
            return json.dumps({"source": "local_fallback", **fallback}, ensure_ascii=False)
    except Exception as e:
        logger.error(f"æœ¬åœ°è·¯ç¶²è¦åŠƒæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}", exc_info=True)

    logger.error(f"âŒ ç„¡æ³•è¦åŠƒè·¯å¾‘ï¼šå¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€ï¼Œæ‰€æœ‰æ–¹æ³•å‡å¤±æ•—ã€‚")
    return json.dumps({"error": f"éå¸¸æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è¦åŠƒå¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€çš„è·¯ç·šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 2. ç¥¨åƒ¹æŸ¥è©¢
# ---------------------------------------------------------------------
@tool
def get_mrt_fare(start_station_name: str, end_station_name: str) -> str:
    """ã€ç¥¨åƒ¹æŸ¥è©¢å°ˆå®¶ã€‘å›å‚³å…¨ç¥¨èˆ‡å…’ç«¥ç¥¨åƒ¹æ ¼ï¼Œä¸å«è·¯å¾‘è¦åŠƒã€‚"""
    logger.info(f"[ç¥¨åƒ¹] {start_station_name} â†’ {end_station_name}")
    try:
        fare = fare_service.get_fare(start_station_name, end_station_name)
        return json.dumps({
            "start_station": start_station_name,
            "end_station":   end_station_name,
            "full_fare":     fare.get("full_fare", "æœªçŸ¥"),
            "child_fare":    fare.get("child_fare", "æœªçŸ¥"),
            "message": (
                f"å¾ã€Œ{start_station_name}ã€åˆ°ã€Œ{end_station_name}ã€çš„"
                f"å…¨ç¥¨ NT${fare.get('full_fare', 'æœªçŸ¥')}ï¼Œ"
                f"å…’ç«¥ç¥¨ NT${fare.get('child_fare', 'æœªçŸ¥')}ã€‚"
            )
        }, ensure_ascii=False)
    except StationNotFoundError as e:
        return json.dumps({"error": str(e)}, ensure_ascii=False)
    except Exception as e:
        logger.exception("ç¥¨åƒ¹æŸ¥è©¢å¤±æ•—")
        return json.dumps({"error": f"æŸ¥è©¢ç¥¨åƒ¹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 3. é¦–æœ«ç­è»Š
# ---------------------------------------------------------------------
@tool
def get_first_last_train_time(station_name: str) -> str:
    """ã€é¦–æœ«ç­è»Šå°ˆå®¶ã€‘æŸ¥è©¢æŒ‡å®šç«™é»å„æ–¹å‘é¦–/æœ«ç­æ™‚é–“ã€‚"""
    logger.info(f"[é¦–æœ«ç­è»Š] {station_name}")
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    timetable = tdx_api.get_first_last_timetable(station_ids[0])
    if not timetable:
        return json.dumps({"error": f"æŸ¥ç„¡ã€Œ{station_name}ã€é¦–æœ«ç­è»Šè³‡è¨Š"}, ensure_ascii=False)

    rows = [
        {"direction": t.get("TripHeadSign", "æœªçŸ¥æ–¹å‘"),
         "first":     t.get("FirstTrainTime", "N/A"),
         "last":      t.get("LastTrainTime", "N/A")}
        for t in timetable
    ]
    msg_lines = [f"ã€Œ{station_name}ã€é¦–æœ«ç­è»Šï¼š"]
    for r in rows:
        msg_lines.append(f"å¾€ {r['direction']} â†’ é¦–ç­ {r['first']}ï¼Œæœ«ç­ {r['last']}")

    return json.dumps({"station": station_name, "timetable": rows,
                       "message": "\n".join(msg_lines)}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 4. å‡ºå£è³‡è¨Š
# ---------------------------------------------------------------------
@tool
def get_station_exit_info(station_name: str) -> str:
    """ã€è»Šç«™å‡ºå£å°ˆå®¶ã€‘åˆ—å‡ºæ‰€æœ‰å‡ºå£ç·¨è™Ÿèˆ‡æè¿°ã€‚"""
    logger.info(f"[å‡ºå£] {station_name}")
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    exit_map = local_data_manager.exits
    exits: list[str] = []
    for sid in station_ids:
        exits.extend(
            f"å‡ºå£ {e.get('ExitNo', 'N/A')}: {e.get('Description', 'ç„¡æè¿°')}"
            for e in exit_map.get(sid, [])
        )

    if not exits:
        return json.dumps({"error": f"æŸ¥ç„¡ã€Œ{station_name}ã€å‡ºå£è³‡è¨Š"}, ensure_ascii=False)

    if all(x.endswith(": ç„¡æè¿°") for x in exits):
        msg = (f"ã€Œ{station_name}ã€å…±æœ‰ {len(exits)} å€‹å‡ºå…¥å£ï¼Œ"
               "ä½†æš«ç„¡è©³ç´°æè¿°ã€‚")
    else:
        msg = f"ã€Œ{station_name}ã€å‡ºå£è³‡è¨Šï¼š\n" + "\n".join(exits)

    return json.dumps({"station": station_name, "exits": exits,
                       "message": msg}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 5. è»Šç«™è¨­æ–½
# ---------------------------------------------------------------------
@tool
def get_station_facilities(station_name: str) -> str:
    """ã€è»Šç«™è¨­æ–½å°ˆå®¶ã€‘åˆ—å‡ºç«™å…§è¨­æ–½èˆ‡æè¿°ã€‚"""
    logger.info(f"[è¨­æ–½] {station_name}")
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    facilities = [
        local_data_manager.facilities.get(sid)
        for sid in station_ids
        if sid in local_data_manager.facilities
    ]
    facilities = [f for f in facilities if f]

    if not facilities:
        return json.dumps({"error": f"æŸ¥ç„¡ã€Œ{station_name}ã€è¨­æ–½è³‡è¨Š"}, ensure_ascii=False)

    desc = "\n".join(facilities)
    msg = (f"ã€Œ{station_name}ã€è¨­æ–½è³‡è¨Šï¼š\n{desc}"
           if desc.strip() != "ç„¡è©³ç´°è³‡è¨Š"
           else f"ã€Œ{station_name}ã€ç›®å‰ç„¡è©³ç´°è¨­æ–½æè¿°è³‡è¨Šã€‚")
    return json.dumps({"station": station_name, "facilities_info": desc,
                       "message": msg}, ensure_ascii=False)

# ---------------------------------------------------------------------
# 6. éºå¤±ç‰©æ™ºæ…§æœå°‹ (æœ€çµ‚ç‰ˆ)
# ---------------------------------------------------------------------
@tool
def search_lost_and_found(
    item_description: str | None = None, 
    station_name: str | None = None,
    date_str: str | None = None
) -> str:
    """
    ã€éºå¤±ç‰©æ™ºæ…§æœå°‹å°ˆå®¶ã€‘
    æ ¹æ“šç‰©å“çš„æ¨¡ç³Šæè¿°ã€å¯èƒ½çš„åœ°é»å’Œæ—¥æœŸï¼ˆä¾‹å¦‚'æ˜¨å¤©'æˆ–'2025/08/02'ï¼‰ä¾†æœå°‹éºå¤±ç‰©ã€‚
    """
    logger.info(f"[æ™ºæ…§éºå¤±ç‰©æœå°‹] æ­£åœ¨æœå°‹: ç‰©å“='{item_description}', è»Šç«™='{station_name}', æ—¥æœŸ='{date_str}'")
    
    if not item_description and not station_name:
        return json.dumps({"error": "ç¼ºå°‘æœå°‹æ¢ä»¶", "message": "è«‹è‡³å°‘å‘Šè¨´æˆ‘ç‰©å“çš„æè¿°æˆ–å¯èƒ½çš„è»Šç«™å–”ï¼"}, ensure_ascii=False)

    # --- ã€âœ¨æ ¸å¿ƒæ“´å……âœ¨ã€‘å»ºç«‹ä¸€å€‹è¶…ç´šè±å¯Œçš„ã€Œç‰©å“åˆ¥ååœ°åœ–ã€ ---
    item_alias_map = {
        # ===== é›»å­ç¥¨è­‰é¡ =====
        "æ‚ éŠå¡": "é›»å­ç¥¨è­‰", "ä¸€å¡é€š": "é›»å­ç¥¨è­‰", "icash": "é›»å­ç¥¨è­‰",
        "æ„›é‡‘å¡": "é›»å­ç¥¨è­‰", "icå¡": "é›»å­ç¥¨è­‰", "å­¸ç”Ÿå¡": "é›»å­ç¥¨è­‰",
        "æ•¬è€å¡": "é›»å­ç¥¨è­‰", "æ„›å¿ƒå¡": "é›»å­ç¥¨è­‰",

        # ===== 3C / é›»å­ç”¢å“é¡ =====
        "æ‰‹æ©Ÿ": "è¡Œå‹•é›»è©±", "iphone": "è¡Œå‹•é›»è©±",
        "airpods": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)", "è—èŠ½è€³æ©Ÿ": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)", "ç„¡ç·šè€³æ©Ÿ": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)",
        "è€³æ©Ÿ": "ä»–é¡(è€³æ©Ÿ",  # ä½¿ç”¨ä¸å®Œæ•´çš„è©ï¼Œä»¥åŒ¹é… "è€³æ©Ÿ)" å’Œ "è€³æ©Ÿ("
        "airpods": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)",
        "airpods pro": "ä»–é¡(è€³æ©Ÿ(ç„¡ç·š)/è—ç‰™)",
        "å……é›»ç·š": "ä»–é¡(å……é›»(å‚³è¼¸)ç·š)", "å¿«å……ç·š": "ä»–é¡(å……é›»(å‚³è¼¸)ç·š)", "å‚³è¼¸ç·š": "ä»–é¡(å……é›»(å‚³è¼¸)ç·š)",
        "å……é›»å™¨": "ä»–é¡(å……é›»å™¨)", "è±†è…é ­": "ä»–é¡(å……é›»å™¨)",
        "è¡Œå‹•é›»æº": "ä»–é¡(è¡Œå‹•é›»æº)", "å……é›»å¯¶": "ä»–é¡(è¡Œå‹•é›»æº)",
        "é›»å­è¸": "ä»–é¡(é›»å­è¸)",
        "ç›¸æ©Ÿ": "ç…§ç›¸æ©Ÿ",

        # ===== è­‰ä»¶ / å¡ç‰‡é¡ =====
        "èº«åˆ†è­‰": "è­‰ä»¶", "å¥ä¿å¡": "è­‰ä»¶", "é§•ç…§": "è­‰ä»¶", "å­¸ç”Ÿè­‰": "è­‰ä»¶",
        "ä¿¡ç”¨å¡": "ä¿¡ç”¨å¡", "é‡‘èå¡": "é‡‘èå¡", "ææ¬¾å¡": "é‡‘èå¡",
        "å¡å¤¾": "è»Šç¥¨å¤¾", "ç¥¨å¡å¤¾": "è»Šç¥¨å¤¾",

        # ===== é›¨å…·é¡ =====
        "é›¨å‚˜": "å‚˜", "é™½å‚˜": "å‚˜",
        "æŠ˜ç–Šå‚˜": "æ‘ºå‚˜",
        "é•·æŸ„å‚˜": "é•·å‚˜",

        # ===== åŒ…åŒ… / è¢‹å­é¡ =====
        "éŒ¢åŒ…": "çš®å¤¾",
        "é›¶éŒ¢è¢‹": "é›¶éŒ¢åŒ…",
        "æè¢‹": "æ‰‹æè¢‹", "è³¼ç‰©è¢‹": "æ‰‹æè¢‹",
        "å¾ŒèƒŒåŒ…": "èƒŒåŒ…", "æ›¸åŒ…": "èƒŒåŒ…",
        "å¡‘è† è¢‹": "å¡‘è† è¢‹",
        "ç´™è¢‹": "ç´™è¢‹",

        # ===== è¡£ç‰© / é£¾å“é¡ =====
        "è¡£æœ": "è¡£ç‰©", "å¤–å¥—": "è¡£ç‰©",
        "å¸½å­": "å¸½å­",
        "æˆ’æŒ‡": "æˆ’æŒ‡", "é¦–é£¾": "é¦–é£¾", "é …éŠ": "é¦–é£¾", "æ‰‹éŠ": "é¦–é£¾", "è€³ç’°": "è€³ç’°",
        "çœ¼é¡": "çœ¼é¡", "å¤ªé™½çœ¼é¡": "çœ¼é¡",
        "æ‰‹éŒ¶": "æ‰‹éŒ¶",

        # ===== å…¶ä»–å¸¸è¦‹ã€Œä»–é¡ã€ç‰©å“ =====
        "ç­†": "ä»–é¡(ç­†)", "åŸå­ç­†": "ä»–é¡(ç­†)",
        "æ‰‹å¸•": "ä»–é¡(æ‰‹å¸•)",
        "æŸå£è¢‹": "ä»–é¡(æŸå£è¢‹)",
        "åŠé£¾": "ä»–é¡(åŠé£¾)", "é‘°åŒ™åœˆ": "ä»–é¡(åŠé£¾)",

        # ===== å…¶ä»–å¸¸è¦‹ç‰©å“ =====
        "é‘°åŒ™": "é‘°åŒ™",
        "æ°´å£º": "æ°´å£º", "ä¿æº«ç“¶": "ä¿æº«ç“¶",
        "å¨ƒå¨ƒ": "ç©å¶", "å…¬ä»”": "ç©å¶",
    }
    # ----------------------------------------------------

    # --- æ­¥é©Ÿ 1: è™•ç†æ—¥æœŸ ---
    search_date = None
    if date_str:
        try:
            if "æ˜¨å¤©" in date_str:
                search_date = (datetime.now() - timedelta(days=1)).strftime('%Y/%m/%d')
            elif "ä»Šå¤©" in date_str:
                search_date = datetime.now().strftime('%Y/%m/%d')
            else:
                search_date = datetime.strptime(date_str, '%Y/%m/%d').strftime('%Y/%m/%d')
            logger.info(f"æ—¥æœŸæ¢ä»¶è§£ææˆåŠŸ: {search_date}")
        except ValueError:
            logger.warning(f"ç„¡æ³•è§£ææ—¥æœŸå­—ä¸²: '{date_str}'ï¼Œå°‡å¿½ç•¥æ—¥æœŸæ¢ä»¶ã€‚")
            pass

    # --- æ­¥é©Ÿ 2: è™•ç†åœ°é» (ç«™å -> ç«™å + è·¯ç·šå) ---
    search_locations = set()
    if station_name:
        norm_station_name = station_name.replace("ç«™", "").replace("é§…", "")
        search_locations.add(norm_station_name)
        
        station_ids = station_manager.get_station_ids(station_name)
        if isinstance(station_ids, list) and station_ids:
            line_prefix_match = re.match(r"([A-Z]+)", station_ids[0])
            if line_prefix_match:
                line_prefix = line_prefix_match.group(1)
                line_map = {'BL': 'æ¿å—ç·š', 'BR': 'æ–‡æ¹–ç·š', 'R': 'æ·¡æ°´ä¿¡ç¾©ç·š', 'G': 'æ¾å±±æ–°åº—ç·š', 'O': 'ä¸­å’Œæ–°è˜†ç·š', 'Y': 'ç’°ç‹€ç·š'}
                line_name = line_map.get(line_prefix)
                if line_name:
                    search_locations.add(line_name)
        logger.info(f"åœ°é»æ¢ä»¶æ“´å±•ç‚º: {search_locations}")

    # --- æ­¥é©Ÿ 3: è™•ç†ç‰©å“ (ç²¾æº–åˆ¥å -> èªæ„æœå°‹) ---
    search_item_terms = set()
    if item_description:
        # 1. å„ªå…ˆä½¿ç”¨ã€Œç²¾æº–åˆ¥åã€é€²è¡Œè½‰æ›
        norm_item_desc = item_description.lower()
        if norm_item_desc in item_alias_map:
            official_item_name = item_alias_map[norm_item_desc]
            search_item_terms.add(official_item_name.lower())
            logger.info(f"ç‰©å“ '{norm_item_desc}' é€éåˆ¥åç²¾æº–åŒ¹é…åˆ° '{official_item_name}'")
        
        # 2. æ¥è‘—ï¼Œä½¿ç”¨ã€Œå‘é‡æœå°‹ã€ä¾†å°‹æ‰¾å…¶ä»–èªæ„ç›¸ä¼¼çš„è©
        found_names = lost_item_search_service.find_similar_items(item_description, top_k=3, threshold=0.6)
        if found_names:
            search_item_terms.update(name.lower() for name in found_names)
            
        # 3. ç„¡è«–å¦‚ä½•ï¼Œéƒ½å°‡ä½¿ç”¨è€…åŸå§‹çš„æè¿°ä¹ŸåŠ å…¥æœå°‹ç›®æ¨™
        search_item_terms.add(norm_item_desc)
        logger.info(f"ç‰©å“æ¢ä»¶æ“´å±•ç‚º: {search_item_terms}")

    # --- æ­¥é©Ÿ 4: è¼‰å…¥è³‡æ–™ä¸¦åŸ·è¡Œæœ€çµ‚ç¯©é¸ ---
    try:
        with open(config.LOST_AND_FOUND_DATA_PATH, 'r', encoding='utf-8') as f:
            all_items = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        logger.error(f"éºå¤±ç‰©è³‡æ–™åº«æª”æ¡ˆéºå¤±æˆ–ææ¯€: {config.LOST_AND_FOUND_DATA_PATH}")
        return json.dumps({"error": "è³‡æ–™åº«éŒ¯èª¤", "message": "æŠ±æ­‰ï¼Œéºå¤±ç‰©è³‡æ–™åº«å¥½åƒä¸è¦‹äº†ã€‚"}, ensure_ascii=False)

    filtered_items = all_items
    if search_date:
        filtered_items = [item for item in filtered_items if item.get('col_Date') == search_date]
    if search_locations:
        filtered_items = [item for item in filtered_items if any(loc.lower() in item.get('col_TRTCStation', '').lower() for loc in search_locations)]
    if search_item_terms:
        filtered_items = [item for item in filtered_items if any(term in item.get('col_LoseName', '').lower() for term in search_item_terms)]

    # --- æ­¥é©Ÿ 5: æ ¼å¼åŒ–ä¸¦å›å‚³çµæœ ---
    top_results = filtered_items[:10]
    
    if not top_results:
        return json.dumps({"count": 0, "message": "å¾ˆæŠ±æ­‰ï¼Œåœ¨è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„éºå¤±ç‰©ã€‚"}, ensure_ascii=False)

    formatted_results = [
        {"æ‹¾ç²æ—¥æœŸ": item.get("col_Date"), "ç‰©å“åç¨±": item.get("col_LoseName"), "æ‹¾ç²è»Šç«™": item.get("col_TRTCStation"), "ä¿ç®¡å–®ä½": item.get("col_NowPlace")}
        for item in top_results
    ]
    
    return json.dumps({
        "count": len(top_results),
        "message": f"å¥½çš„ï¼Œå¹«æ‚¨åœ¨è³‡æ–™åº«ä¸­æ‰¾åˆ°äº† {len(top_results)} ç­†æœ€ç›¸é—œçš„éºå¤±ç‰©è³‡è¨Šï¼š",
        "results": formatted_results
    }, ensure_ascii=False, indent=2)

# ---------------------------------------------------------------------
# 7. æ·é‹ç¾é£Ÿæœå°‹ (æ–°åŠŸèƒ½)
# ---------------------------------------------------------------------
@tool
def search_mrt_food(station_name: str) -> str:
    """
    ã€æ·é‹ç¾é£Ÿå®¶ã€‘
    æ ¹æ“šä½¿ç”¨è€…æä¾›çš„æ·é‹ç«™åï¼ŒæŸ¥è©¢è©²ç«™é™„è¿‘æ¨è–¦çš„ç¾é£Ÿã€‚
    """
    logger.info(f"[ç¾é£Ÿæœå°‹] æ­£åœ¨æœå°‹ã€Œ{station_name}ã€é™„è¿‘çš„ç¾é£Ÿ...")

    # 1. é©—è­‰ä¸¦å–å¾—æ¨™æº–åŒ–çš„ç«™å
    # æˆ‘å€‘ä½¿ç”¨ station_manager ä¾†ç¢ºä¿ä½¿ç”¨è€…è¼¸å…¥çš„æ˜¯ä¸€å€‹æœ‰æ•ˆçš„ç«™å
    station_ids = station_manager.get_station_ids(station_name)
    if not station_ids:
        # å¦‚æœæ‰¾ä¸åˆ°ç«™åï¼Œè¿”å›ä¸€å€‹å‹å–„çš„éŒ¯èª¤è¨Šæ¯
        return json.dumps({"error": f"æ‰¾ä¸åˆ°è»Šç«™ã€Œ{station_name}ã€ã€‚"}, ensure_ascii=False)

    # 2. è¼‰å…¥ç¾é£Ÿåœ°åœ–è³‡æ–™
    food_map = local_data_manager.food_map
    if not food_map:
        return json.dumps({"error": "ç¾é£Ÿåœ°åœ–è³‡æ–™å°šæœªè¼‰å…¥ã€‚"}, ensure_ascii=False)
        
    # 3. é€²è¡Œæœå°‹
    # æˆ‘å€‘éœ€è¦å¾ station_map ä¸­æ‰¾åˆ°å®˜æ–¹ä¸­æ–‡ç«™åï¼Œä»¥ä¾¿å’Œç¾é£Ÿåœ°åœ–çš„ key é€²è¡Œæ¯”å°
    # (æ­¤è™•ç°¡åŒ–é‚è¼¯ï¼Œå‡è¨­ station_manager.get_station_ids èƒ½è™•ç†å¥½åˆ¥åå•é¡Œï¼Œä¸¦ä»¥å®˜æ–¹åç‚ºä¸»)
    # æˆ‘å€‘éœ€è¦ä¸€å€‹æ–¹æ³•å¾ TDX ID åæŸ¥å›å®˜æ–¹ä¸­æ–‡å
    # é€™è£¡æˆ‘å€‘ç”¨ä¸€å€‹ç°¡åŒ–é‚è¼¯ï¼šç›´æ¥ç”¨ä½¿ç”¨è€…è¼¸å…¥çš„ï¼ˆæˆ–æ¨™æº–åŒ–å¾Œçš„ï¼‰ç«™åå»æ¯”å°
    
    # å°å…¥æ¨™æº–åŒ–å·¥å…·
    from utils.station_name_normalizer import normalize_station_name
    norm_station_name = normalize_station_name(station_name)

    found_restaurants = []
    for entry in food_map:
        # å°ç¾é£Ÿåœ°åœ–ä¸­çš„ç«™åä¹Ÿé€²è¡Œæ¨™æº–åŒ–ï¼Œä»¥å¢åŠ åŒ¹é…æˆåŠŸç‡
        if normalize_station_name(entry.get("station")) == norm_station_name:
            found_restaurants = entry.get("restaurants", [])
            break # æ‰¾åˆ°å°æ‡‰çš„ç«™é»å¾Œå°±è·³å‡ºè¿´åœˆ

    if not found_restaurants:
        return json.dumps({
            "station": station_name,
            "count": 0,
            "message": f"å“å‘€ï¼Œæˆ‘ç›®å‰é‚„æ²’æœ‰æ”¶è—ã€Œ{station_name}ã€é™„è¿‘çš„ç¾é£Ÿè³‡è¨Šè€¶ã€‚"
        }, ensure_ascii=False)

    # 4. æ ¼å¼åŒ–ä¸¦å›å‚³çµæœ
    return json.dumps({
        "station": station_name,
        "count": len(found_restaurants),
        "message": f"å¥½çš„ï¼Œå¹«æ‚¨æ‰¾åˆ°äº† {len(found_restaurants)} å®¶åœ¨ã€Œ{station_name}ã€é™„è¿‘çš„ç¾é£Ÿï¼š",
        "restaurants": found_restaurants
    }, ensure_ascii=False, indent=2)

# ---------------------------------------------------------------------
# åŒ¯å‡ºå·¥å…·æ¸…å–®
# ---------------------------------------------------------------------
all_tools = [
    plan_route,
    get_mrt_fare,
    get_first_last_train_time,
    get_station_exit_info,
    get_station_facilities,
    search_lost_and_found,
    search_mrt_food,
]
