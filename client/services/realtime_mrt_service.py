# services/realtime_mrt_service.py
import json
import os
import threading
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import faiss
import numpy as np
import uuid

# å‡è¨­é€™äº›æ˜¯æ‚¨çš„å…¶ä»–ä¾è³´
# æ‚¨åŸæœ¬ä½¿ç”¨çš„ metro_soap_service.py
from services.metro_soap_service import MetroSoapService 
# æ‚¨åŸæœ¬çš„ station_service.py
from services.station_service import StationManager 
from utils.time_parser import parse_countdown_to_seconds

logger = logging.getLogger(__name__)

# Define constants for data paths
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(PROJECT_ROOT, 'data')
DEFAULT_DB_PATH = os.path.join(DATA_DIR, "realtime_train_db.json")
DEFAULT_INDEX_PATH = os.path.join(DATA_DIR, "station_index.faiss")

class RealtimeMRTService:
    def __init__(self, metro_soap_api: MetroSoapService, station_manager: StationManager, update_interval_seconds: int = 15, db_path: str = DEFAULT_DB_PATH, index_path: str = DEFAULT_INDEX_PATH):
        self.metro_soap_api = metro_soap_api
        self.station_manager = station_manager
        self.update_interval_seconds = update_interval_seconds
        self.db_path = db_path
        self.index_path = index_path
        self._cached_train_info: List[Dict[str, Any]] = []
        self._cache_timestamp: Optional[datetime] = None
        self._stop_event = threading.Event()
        self._update_thread: Optional[threading.Thread] = None
        self._is_running = False
        self._station_index = None
        self._station_names_list: List[str] = []

        self._load_local_db_and_update_sync()
        self._init_faiss_index()
        logger.info(f"--- RealtimeMRTService åˆå§‹åŒ–ï¼Œæ•¸æ“šæ¯ {update_interval_seconds} ç§’åˆ·æ–°ï¼ŒDB å­˜æ–¼ {db_path} ---")

    def _load_local_db_and_update_sync(self):
        """å¾æœ¬åœ° DB è¼‰å…¥æ•¸æ“šï¼Œä¸¦å˜—è©¦ç«‹å³åŒæ­¥æ›´æ–°ã€‚"""
        self._load_local_db()
        # å¦‚æœå¿«å–æ²’æœ‰æ•¸æ“šæˆ–å·²éæœŸï¼Œå‰‡ç«‹å³åŒæ­¥æ›´æ–°
        if not self._cached_train_info or (self._cache_timestamp and (datetime.now() - self._cache_timestamp).total_seconds() > self.update_interval_seconds):
            logger.info("--- ğŸ”„ æœ¬åœ°æ•¸æ“šéæœŸæˆ–ç‚ºç©ºï¼Œæ­£åœ¨é€²è¡ŒåŒæ­¥æ›´æ–°... ---")
            self.update_cache_sync()
        else:
            logger.info("--- âœ… æœ¬åœ°æ•¸æ“šä»ç„¶æœ‰æ•ˆï¼Œç„¡éœ€åŒæ­¥æ›´æ–°ã€‚ ---")

    def update_cache_sync(self):
        """åŒæ­¥æ–¹å¼åˆ·æ–°ç·©å­˜ï¼Œç”¨æ–¼æ‡‰æ€¥ã€‚"""
        try:
            all_track_info = self.metro_soap_api.get_realtime_track_info()
            if all_track_info:
                self._cached_train_info = all_track_info
                self._cache_timestamp = datetime.now()
                os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
                with open(self.db_path, 'w', encoding='utf-8') as f:
                    # æ¯æ¬¡å¯«å…¥éƒ½æ˜¯å…¨æ–°çš„æ•¸æ“šï¼ŒèˆŠæ•¸æ“šæœƒè¢«è¦†è“‹ï¼Œå¯¦ç¾ã€Œæ¸…æ´—ã€
                    json.dump({"timestamp": self._cache_timestamp.isoformat(), "trains": all_track_info}, f, ensure_ascii=False, indent=2)
                logger.info(f"--- âœ… åŒæ­¥ç·©å­˜åˆ·æ–°å®Œæˆï¼Œå…± {len(all_track_info)} ç­†åˆ—è»Šè³‡è¨Š ---")
                return True
            else:
                logger.warning("--- âš ï¸ æœªå¾ Metro API ç²å–åˆ°ä»»ä½•åˆ—è»Šè³‡è¨Š (åŒæ­¥å‘¼å«) ---")
        except Exception as e:
            logger.error(f"--- âŒ åŒæ­¥åˆ·æ–°ç·©å­˜æ™‚ç™¼ç”ŸéŒ¯èª¤: {e} ---", exc_info=True)
        return False

    def _load_local_db(self):
        """å¾æœ¬åœ° JSON è³‡æ–™åº«è¼‰å…¥æ•¸æ“šã€‚"""
        if os.path.exists(self.db_path):
            try:
                with open(self.db_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self._cached_train_info = data.get("trains", [])
                    timestamp_str = data.get("timestamp")
                    if timestamp_str:
                        self._cache_timestamp = datetime.fromisoformat(timestamp_str)
                    logger.info(f"--- âœ… å¾ {self.db_path} è¼‰å…¥æœ¬åœ°åˆ—è»Šç·©å­˜ (å…± {len(self._cached_train_info)} ç­†) ---")
            except Exception as e:
                logger.error(f"--- âŒ è¼‰å…¥æœ¬åœ°åˆ—è»Šç·©å­˜æ™‚ç™¼ç”ŸéŒ¯èª¤: {e} ---", exc_info=True)
    
    def _init_faiss_index(self):
        """åˆå§‹åŒ– FAISS ç´¢å¼•ï¼ŒåŸºæ–¼ç«™ååµŒå…¥å‘é‡ã€‚"""
        self._station_names_list = list(self.station_manager.station_map.keys())
        
        if not self._station_names_list:
            logger.warning("--- âš ï¸ StationManager ä¸­æ²’æœ‰å¯ç”¨çš„ç«™åï¼ŒFAISS ç´¢å¼•ç„¡æ³•åˆå§‹åŒ– ---")
            return

        embedding_dim = 128
        if os.path.exists(self.index_path):
            try:
                self._station_index = faiss.read_index(self.index_path)
                logger.info(f"--- âœ… å¾ {self.index_path} è¼‰å…¥ FAISS ç´¢å¼• ---")
            except Exception as e:
                logger.error(f"--- âŒ è¼‰å…¥ FAISS ç´¢å¼•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ï¼Œå°‡é‡æ–°å‰µå»º ---", exc_info=True)
                self._station_index = None

        if self._station_index is None:
            logger.info("--- ğŸ”„ æ­£åœ¨å‰µå»ºæ–°çš„ FAISS ç´¢å¼• ---")
            station_embeddings = np.array([
                np.frombuffer(uuid.uuid5(uuid.NAMESPACE_DNS, name.lower()).bytes, dtype=np.uint8)[:embedding_dim].astype('float32') / 255.0
                for name in self._station_names_list
            ])
            
            # ç¢ºä¿åµŒå…¥ç¶­åº¦æ­£ç¢º
            if station_embeddings.shape[1] < embedding_dim:
                padded_embeddings = np.zeros((station_embeddings.shape[0], embedding_dim), dtype='float32')
                padded_embeddings[:, :station_embeddings.shape[1]] = station_embeddings
                station_embeddings = padded_embeddings
            elif station_embeddings.shape[1] > embedding_dim:
                station_embeddings = station_embeddings[:, :embedding_dim]

            if station_embeddings.shape[1] != embedding_dim:
                logger.error(f"ç”Ÿæˆçš„ç«™ååµŒå…¥ç¶­åº¦ä¸æ­£ç¢º: {station_embeddings.shape[1]} vs {embedding_dim}")
                return

            self._station_index = faiss.IndexFlatL2(embedding_dim)
            self._station_index.add(station_embeddings)
            try:
                os.makedirs(DATA_DIR, exist_ok=True)
                faiss.write_index(self._station_index, self.index_path)
            except Exception as e:
                logger.error(f"--- âŒ ä¿å­˜ FAISS ç´¢å¼•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e} ---", exc_info=True)
                self._station_index = None

    def start_update_thread(self):
        if not self._is_running:
            self._stop_event.clear()
            self._update_thread = threading.Thread(target=self._periodic_update_cache, daemon=True)
            self._update_thread.start()
            self._is_running = True
            logger.info("--- RealtimeMRTService æ›´æ–°ç·šç¨‹å·²å•Ÿå‹• ---")

    def stop_update_thread(self):
        if self._is_running:
            self._stop_event.set()
            if self._update_thread:
                self._update_thread.join(timeout=self.update_interval_seconds + 5)
            self._is_running = False
            logger.info("--- RealtimeMRTService æ›´æ–°ç·šç¨‹å·²åœæ­¢ ---")

    def _periodic_update_cache(self):
        while not self._stop_event.is_set():
            logger.info("--- RealtimeMRTService: æ­£åœ¨åˆ·æ–°å³æ™‚åˆ—è»Šè³‡è¨Šç·©å­˜... ---")
            try:
                all_track_info = self.metro_soap_api.get_realtime_track_info()
                if all_track_info:
                    self._cached_train_info = all_track_info
                    self._cache_timestamp = datetime.now()
                    os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
                    with open(self.db_path, 'w', encoding='utf-8') as f:
                        json.dump({"timestamp": self._cache_timestamp.isoformat(), "trains": all_track_info}, f, ensure_ascii=False, indent=2)
                    logger.info(f"--- âœ… ç·©å­˜åˆ·æ–°å®Œæˆï¼Œå…± {len(all_track_info)} ç­†åˆ—è»Šè³‡è¨Šï¼Œå­˜è‡³ {self.db_path} ---")
                else:
                    logger.warning("--- âš ï¸ æœªå¾ Metro API ç²å–åˆ°ä»»ä½•åˆ—è»Šè³‡è¨Š ---")
            except Exception as e:
                logger.error(f"--- âŒ åˆ·æ–°ç·©å­˜æ™‚ç™¼ç”ŸéŒ¯èª¤: {e} ---", exc_info=True)
            self._stop_event.wait(self.update_interval_seconds)

    def get_realtime_train_info(self) -> List[Dict[str, Any]]:
        """
        ç²å–æœ€æ–°çš„å³æ™‚åˆ—è»Šè³‡è¨Šã€‚
        å¦‚æœç·©å­˜éæœŸï¼Œå‰‡æœƒå˜—è©¦åŒæ­¥åˆ·æ–°ã€‚å¦‚æœåŒæ­¥åˆ·æ–°å¤±æ•—ï¼Œæœƒå¾æœ¬åœ° DB è®€å–æœ€è¿‘çš„æ•¸æ“šã€‚
        """
        # æª¢æŸ¥ç·©å­˜æ˜¯å¦ä»æœ‰æ•ˆ
        if self._cache_timestamp and (datetime.now() - self._cache_timestamp).total_seconds() < self.update_interval_seconds:
            logger.info("--- âœ… åˆ—è»Šç·©å­˜ä»ç„¶æœ‰æ•ˆ ---")
            return self._cached_train_info
        
        # ç·©å­˜éæœŸï¼Œç«‹å³å˜—è©¦åŒæ­¥åˆ·æ–°
        logger.warning("--- âš ï¸ åˆ—è»Šç·©å­˜æ•¸æ“šå·²éæœŸï¼Œæ­£åœ¨å˜—è©¦åŒæ­¥ç²å–æœ€æ–°è³‡æ–™... ---")
        if self.update_cache_sync():
            return self._cached_train_info
        else:
            # å¦‚æœåŒæ­¥åˆ·æ–°å¤±æ•—ï¼Œå‰‡å˜—è©¦å¾æœ¬åœ° DB è®€å–æœ€è¿‘çš„æ•¸æ“šï¼ˆå³ä½¿å¯èƒ½ç¨èˆŠï¼‰
            self._load_local_db()
            if self._cached_train_info:
                logger.warning("--- âŒ åŒæ­¥åˆ·æ–°å¤±æ•—ï¼Œå›å‚³éæœŸä½†å°šå¯ç”¨çš„æœ¬åœ° DB è³‡æ–™ã€‚---")
                return self._cached_train_info
            
        logger.error("--- âŒ ç„¡æ³•ç²å–ä»»ä½•åˆ—è»Šè³‡è¨Šï¼Œè«‹æª¢æŸ¥ API é€£ç·šèˆ‡è¨­å®šã€‚ ---")
        return []

    def get_next_train_info(self, target_station_official_name: str, target_direction_normalized_list: List[str]) -> List[Dict[str, Any]]:
        """
        ç²å–é‡å°ç‰¹å®šè»Šç«™å’Œæ–¹å‘ç¯©é¸å¾Œçš„åˆ—è»Šè³‡è¨Šã€‚
        """
        all_train_info = self.get_realtime_train_info()
        if not all_train_info:
            logger.warning("--- âš ï¸ ç„¡æ³•ç²å–åˆ—è»Šè³‡è¨Šä»¥ç¯©é¸ä¸‹ä¸€ç­åˆ—è»Šã€‚ ---")
            return []
        
        target_station_normalized = self.station_manager._normalize_name_for_map(target_station_official_name)
        candidate_trains = []

        for train in all_train_info:
            train_current_station_raw = train.get('StationName')
            train_destination_raw = train.get('DestinationName')
            countdown_str = train.get('CountDown', '')

            train_current_station_normalized = self.station_manager._normalize_name_for_map(train_current_station_raw)
            train_destination_normalized = self.station_manager._normalize_name_for_map(train_destination_raw)

            countdown_seconds = parse_countdown_to_seconds(countdown_str)
            if countdown_seconds == float('inf'):
                continue

            if train_destination_normalized in target_direction_normalized_list:
                # ç°¡åŒ–åˆ¤æ–·é‚è¼¯ï¼šåªæª¢æŸ¥åˆ—è»Šç•¶å‰ç«™æ˜¯å¦ç‚ºç›®æ¨™ç«™æˆ–ç›®æ¨™ç«™çš„é„°è¿‘ç«™
                # ç”±æ–¼ MetroSoapService API çš„è³‡æ–™æ ¼å¼å¯èƒ½èˆ‡ TDX API ä¸åŒï¼Œæˆ‘å€‘å‡è¨­
                # é€™è£¡çš„ "StationName" æ˜¯æŒ‡åˆ—è»Šç›®å‰æ‰€åœ¨çš„è»Šç«™ã€‚
                if train_current_station_normalized == target_station_normalized:
                    candidate_trains.append(train)

        candidate_trains.sort(key=lambda x: parse_countdown_to_seconds(x.get('CountDown', '')))
        
        return candidate_trains

    def search_station(self, query: str) -> Optional[str]:
        """
        ã€é‡è¦ã€‘å„ªå…ˆä½¿ç”¨ç²¾ç¢ºåŒ¹é…ï¼Œå¤±æ•—å¾Œæ‰ä½¿ç”¨ FAISS æ¨¡ç³ŠåŒ¹é…ã€‚
        """
        # æ­¥é©Ÿ1: å˜—è©¦ç²¾ç¢ºåŒ¹é…ï¼ˆåŒ…å«åˆ¥åï¼‰
        resolved_name_by_manager = self.station_manager.resolve_station_alias(query)
        if self.station_manager.get_station_ids(resolved_name_by_manager):
            logger.info(f"--- ç²¾ç¢ºåŒ¹é… '{query}' æˆåŠŸï¼Œè§£æç‚º '{resolved_name_by_manager}' ---")
            return resolved_name_by_manager

        # æ­¥é©Ÿ2: å¦‚æœç²¾ç¢ºåŒ¹é…å¤±æ•—ï¼Œæ‰ä½¿ç”¨ FAISS é€²è¡Œæ¨¡ç³ŠåŒ¹é…
        if self._station_index is None or not self._station_names_list:
            logger.warning("--- âš ï¸ FAISS ç´¢å¼•æœªåˆå§‹åŒ–æˆ–ç«™ååˆ—è¡¨ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œæ¨¡ç³Šæœç´¢ ---")
            return None

        embedding_dim = self._station_index.d
        query_embedding_bytes = uuid.uuid5(uuid.NAMESPACE_DNS, query.lower()).bytes
        query_embedding = np.zeros(embedding_dim, dtype='float32')
        temp_embedding = np.frombuffer(query_embedding_bytes, dtype=np.uint8).astype('float32') / 255.0
        query_embedding[:min(embedding_dim, temp_embedding.shape[0])] = temp_embedding[:min(embedding_dim, temp_embedding.shape[0])]
        query_embedding = query_embedding.reshape(1, -1)

        try:
            # ä¿®æ­£: èª¿æ•´ L2 è·é›¢é–¾å€¼
            faiss_l2_distance_threshold = 1.0
            distances, indices = self._station_index.search(query_embedding, k=1)
            
            if distances[0][0] <= faiss_l2_distance_threshold:
                resolved_name_by_faiss = self._station_names_list[indices[0][0]]
                logger.info(f"--- FAISS æ¨¡ç³Šæœç´¢ '{query}' æˆåŠŸï¼Œè§£æç‚º '{resolved_name_by_faiss}' (L2è·é›¢: {distances[0][0]:.4f}) ---")
                return resolved_name_by_faiss
            else:
                logger.info(f"--- FAISS æœç´¢ '{query}' æœªæ‰¾åˆ°é«˜ç›¸ä¼¼åº¦çµæœ (L2è·é›¢: {distances[0][0]:.4f}) ---")
        except Exception as e:
            logger.error(f"--- âŒ FAISS æœç´¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e} ---", exc_info=True)
        
        return None

    def resolve_train_terminus(self, start_station_name: str, intermediate_destination: str) -> List[str]:
        """
        æ ¹æ“šèµ·é»å’Œä¸­é–“ç«™é»ï¼Œæ¨å°å‡ºå¯èƒ½çš„åˆ—è»Šçµ‚é»ç«™ã€‚
        """
        # ä½¿ç”¨ StationManager çš„ resolve_direction æ–¹æ³•ï¼Œé€™å€‹æ–¹æ³•å·²ç¶“åŒ…å«äº†æ‰€æœ‰é‚è¼¯
        # å®ƒæœƒå°‡ã€Œå¾€æ·¡æ°´ã€é€™é¡çš„æŒ‡ä»¤è§£æç‚ºå¯¦éš›çš„çµ‚é»ç«™åç¨±ï¼Œä¸¦è™•ç†åˆ¥å
        resolved_terminus = self.station_manager.resolve_direction(start_station_name, intermediate_destination)
        
        if not resolved_terminus:
            logger.warning(f"--- âš ï¸ ç„¡æ³•å¾ '{start_station_name}' å¾€ '{intermediate_destination}' æ¨å°å‡ºå¯èƒ½çš„çµ‚é»ç«™ ---")
        
        return resolved_terminus
    
    # é€™æ˜¯ç‚ºäº†é…åˆå·¥å…·å‡½å¼è€Œæ–°å¢çš„å…¥å£æ–¹æ³•
    def get_arrival_info(self, station_name: str, destination_name: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        ç²å–ç‰¹å®šç«™é»çš„åˆ—è»Šåˆ°ç«™è³‡è¨Šã€‚
        
        Args:
            station_name (str): ä½¿ç”¨è€…æŸ¥è©¢çš„ç«™é»åç¨±ï¼Œå¯èƒ½ç‚ºåˆ¥åã€‚
            destination_name (Optional[str]): åˆ—è»Šè¡Œé§›çš„çµ‚é»ç«™åç¨±ï¼Œå¯èƒ½ç‚ºåˆ¥åæˆ–æ¨¡ç³Šæ–¹å‘ã€‚
            
        Returns:
            List[Dict[str, Any]]: åŒ…å«åˆ—è»Šåˆ°ç«™è³‡è¨Šçš„åˆ—è¡¨ï¼Œæˆ–ä¸€å€‹ç©ºåˆ—è¡¨ã€‚
        """
        # 1. è§£æç«™åï¼šå°‡ä½¿ç”¨è€…è¼¸å…¥çš„ç«™åè§£æç‚ºæ¨™æº–åŒ–çš„å®˜æ–¹åç¨±
        resolved_station_name = self.search_station(station_name)
        if not resolved_station_name:
            logger.error(f"ç„¡æ³•è§£ææŸ¥è©¢ç«™é»åç¨±: '{station_name}'")
            return []

        # 2. è§£ææ–¹å‘ï¼šæ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„çµ‚é»ç«™åç¨±
        if destination_name:
            resolved_directions = self.resolve_train_terminus(resolved_station_name, destination_name)
            if not resolved_directions:
                logger.warning(f"ç„¡æ³•è§£æå¾ '{station_name}' å¾€ '{destination_name}' çš„æ–¹å‘ã€‚")
                return []
        else:
            # å¦‚æœæ²’æœ‰æŒ‡å®šæ–¹å‘ï¼Œå‰‡ç²å–è©²ç«™é»æ‰€æœ‰ç·šè·¯çš„æ‰€æœ‰çµ‚é»ç«™
            resolved_directions = self.station_manager.get_terminal_stations_for(resolved_station_name)
            
        # 3. æ ¹æ“šè§£æå¾Œçš„ç«™åå’Œæ–¹å‘ï¼Œå¾å¿«å–ä¸­ç¯©é¸åˆ—è»Šè³‡è¨Š
        filtered_data = self.get_next_train_info(resolved_station_name, resolved_directions)
        
        return filtered_data