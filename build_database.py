# build_database.py

import os
import json
import re
import time
import config
from services.tdx_service import tdx_api
import argparse # âœ¨ æ–°å¢é€™ä¸€è¡Œ
import requests
from bs4 import BeautifulSoup
import pandas as pd # ç¢ºä¿é ‚éƒ¨æœ‰ import pandas

# --- ã€âœ¨æ ¸å¿ƒæ–°å¢âœ¨ã€‘ç¢ºä¿æ‚¨åœ¨æª”æ¡ˆæœ€ä¸Šæ–¹ï¼ŒåŒ¯å…¥äº† metro_soap_api ---
from services.metro_soap_service import metro_soap_api

# ç‚ºäº†é¿å…å¾ªç’°ä¾è³´å’Œç°¡åŒ–ï¼Œæˆ‘å€‘åœ¨é€™è£¡é‡æ–°å®šç¾©ä¸€å€‹èˆ‡ StationManager å…§éƒ¨é‚è¼¯ç›¸åŒçš„ normalize_name å‡½æ•¸ã€‚
def normalize_name(name: str) -> str:
    """æ¨™æº–åŒ–ç«™é»åç¨±ï¼šå°å¯«ã€ç§»é™¤æ‹¬è™Ÿå…§å®¹ã€ç§»é™¤ã€Œç«™ã€ã€ç¹è½‰ç°¡"""
    if not name: return ""
    name = name.lower().strip().replace("è‡º", "å°")
    name = re.sub(r"[\(ï¼ˆ].*?[\)ï¼‰]", "", name).strip()
    
    # --- ã€âœ¨æ ¸å¿ƒä¿®æ­£âœ¨ã€‘ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼ç§»é™¤å­—å°¾ ---
    if name.endswith("ç«™"):
        name = name.removesuffix("ç«™")
        
    return name

# --- âœ¨ã€æ ¸å¿ƒä¿®æ”¹ï¼šä»¥æœ¬åœ° SID Map ç‚ºä¸»çš„å…¨æ–°å‡½å¼ã€‘âœ¨ ---
def build_station_database():
    """
    å¾æœ¬åœ°æœ€å®Œæ•´çš„ stations_sid_map.json å»ºç«‹ç«™é»è³‡æ–™åº«ï¼Œ
    ä¸¦å¾ TDX API è£œå……è‹±æ–‡ç«™åï¼Œæœ€å¾Œæ•´åˆè©³ç´°åˆ¥åã€‚
    """
    print("\n--- [1/6] æ­£åœ¨å»ºç«‹ã€Œç«™é»è³‡æ–™åº«ã€(ä¸»è¦ä¾†æº: stations_sid_map.json)... ---")
    
    sid_map_path = config.STATIONS_SID_MAP_PATH
    if not os.path.exists(sid_map_path):
        print(f"--- âŒ æ­¥é©Ÿ 1 å¤±æ•—: æ‰¾ä¸åˆ°æ ¸å¿ƒè³‡æ–™æª” {sid_map_path} ---")
        return

    # 1. è®€å–æœ€å®Œæ•´çš„ SID Map ä½œç‚ºåŸºç¤
    with open(sid_map_path, 'r', encoding='utf-8') as f:
        sid_map_data = json.load(f)

    # 2. å¾ TDX API ç²å–è³‡æ–™ï¼Œåƒ…ç”¨æ–¼è£œå……è‹±æ–‡ç«™å
    print("--- æ­£åœ¨å¾ TDX API ç²å–è‹±æ–‡ç«™åè£œå……è³‡æ–™... ---")
    tdx_stations = tdx_api.get_all_stations()
    tdx_id_to_en_name = {}
    if tdx_stations:
        for station in tdx_stations:
            station_id = station.get("StationID")
            en_name = station.get("StationName", {}).get("En")
            if station_id and en_name:
                tdx_id_to_en_name[station_id] = en_name

    station_map = {}
    
    # 3. éæ­· SID Mapï¼Œå»ºç«‹åŸºç¤çš„ ä¸­æ–‡å -> [IDåˆ—è¡¨] æ˜ å°„
    for item in sid_map_data:
        zh_name = item.get("SCNAME")
        tdx_id = item.get("SCODE")
        if zh_name and tdx_id:
            # å¿½ç•¥åœ°ä¸‹è¡—ç­‰éæ·é‹ç«™çš„SCODE
            if 'MALL' in tdx_id: continue
            
            norm_zh_name = normalize_name(zh_name)
            station_map.setdefault(norm_zh_name, set()).add(tdx_id)

            # è£œå……è‹±æ–‡åç¨±
            if tdx_id in tdx_id_to_en_name:
                norm_en_name = normalize_name(tdx_id_to_en_name[tdx_id])
                station_map.setdefault(norm_en_name, set()).add(tdx_id)

    # 4. æ•´åˆæ‚¨æä¾›çš„è¶…è©³ç´°åˆ¥ååœ°åœ–
    alias_map = {
        # === å¸¸ç”¨ç¸®å¯«/ç°¡ç¨± ===
        "åŒ—è»Š": "å°åŒ—è»Šç«™", "å°è»Š": "å°åŒ—è»Šç«™",
        "å¸‚åºœ": "å¸‚æ”¿åºœ",
        "æ¾æ©Ÿ": "æ¾å±±æ©Ÿå ´",
        "åœ‹é¤¨": "åœ‹çˆ¶ç´€å¿µé¤¨",
        "ä¸­ç´€": "ä¸­æ­£ç´€å¿µå ‚", "ä¸­æ­£å»Ÿ": "ä¸­æ­£ç´€å¿µå ‚",
        "å—å±•": "å—æ¸¯å±•è¦½é¤¨", "å—å±•é¤¨": "å—æ¸¯å±•è¦½é¤¨",
        "å¤§å®‰æ£®": "å¤§å®‰æ£®æ—å…¬åœ’", "æ£®æ—å…¬åœ’": "å¤§å®‰æ£®æ—å…¬åœ’",
        "è¥¿é–€ç”º": "è¥¿é–€",
        "ç¾éº—è¯": "åŠå—è·¯",
        "åŒ—è—": "åŠå—è·¯",
        "å…§ç§‘": "å…§æ¹–",
        "å—è»Ÿ": "å—æ¸¯è»Ÿé«”åœ’å€",
        "æ–°ç”¢åœ’å€": "æ–°åŒ—ç”¢æ¥­åœ’å€",

        # === è‹±æ–‡/æ‹¼éŸ³ ===
        "Taipei Main Station": "å°åŒ—è»Šç«™", "Taipei Main": "å°åŒ—è»Šç«™",
        "Taipei 101": "å°åŒ—101/ä¸–è²¿", "Taipei 101 Station": "å°åŒ—101/ä¸–è²¿", "World Trade Center": "å°åŒ—101/ä¸–è²¿",
        "Songshan Airport": "æ¾å±±æ©Ÿå ´",
        "Taipei Zoo": "å‹•ç‰©åœ’", "Tpe Zoo": "å‹•ç‰©åœ’", "Muzha Zoo": "å‹•ç‰©åœ’",
        "Ximen": "è¥¿é–€",
        "Shilin": "å£«æ—",
        "Longshan Temple": "é¾å±±å¯º",
        "Miramar": "åŠå—è·¯",
        
        # === æ—¥æ–‡æ¼¢å­— ===
        "å°åŒ—é§…": "å°åŒ—è»Šç«™",
        "å¸‚æ”¿åºœé§…": "å¸‚æ”¿åºœ",
        "å°åŒ—101é§…": "å°åŒ—101/ä¸–è²¿",
        "å‹•ç‰©åœ’é§…": "å‹•ç‰©åœ’",

        # === å£èª/åœ°æ¨™/éŒ¯å­— ===
        "101": "å°åŒ—101/ä¸–è²¿", "101å¤§æ¨“": "å°åŒ—101/ä¸–è²¿",
        "ä¸–è²¿": "å°åŒ—101/ä¸–è²¿", "ä¸–è²¿ä¸­å¿ƒ": "å°åŒ—101/ä¸–è²¿",
        "æœ¨æŸµå‹•ç‰©åœ’": "å‹•ç‰©åœ’",
        "å£«æ·‹": "å£«æ—", # å¸¸è¦‹éŒ¯å­—
        "é—œåº¦": "é—œæ¸¡",

        # ===== åœ°æ¨™èˆ‡å•†åœˆ (Landmarks & Shopping Districts) =====
        "SOGO": "å¿ å­å¾©èˆˆ",
        "æ°¸åº·è¡—": "æ±é–€",
        "å°å¤§": "å…¬é¤¨",
        "å¸«å¤§å¤œå¸‚": "å°é›»å¤§æ¨“",
        "å¯§å¤å¤œå¸‚": "é›™é€£",
        "é¥’æ²³å¤œå¸‚": "æ¾å±±",
        "å£«æ—å¤œå¸‚": "åŠæ½­",
        "æ–°å…‰ä¸‰è¶Š": "ä¸­å±±",
        "è¯å±±æ–‡å‰µ": "å¿ å­æ–°ç”Ÿ",
        "æ¾è¸": "åœ‹çˆ¶ç´€å¿µé¤¨",
        "å…‰è¯å•†å ´": "å¿ å­æ–°ç”Ÿ",
        "ä¸‰å‰µ": "å¿ å­æ–°ç”Ÿ",
        "è²“çºœ": "å‹•ç‰©åœ’",
        "æº«æ³‰": "æ–°åŒ—æŠ•",
        "æ¼äººç¢¼é ­": "æ·¡æ°´",
        "å¤§ç¨»åŸ•": "åŒ—é–€",
        "èŠ±åš": "åœ“å±±",
        "è¡Œå¤©å®®æ‹œæ‹œ": "è¡Œå¤©å®®",
        "å—é–€å¸‚å ´": "ä¸­æ­£ç´€å¿µå ‚",

        # ===== é†«é™¢èˆ‡å­¸æ ¡ (Hospitals & Schools) =====
        "æ¦®ç¸½": "çŸ³ç‰Œ",
        "å°å¤§åˆ†é™¢": "å°å¤§é†«é™¢",
        "å¸«å¤§": "å¤äº­",
        "å°ç§‘å¤§": "å…¬é¤¨",
        "åŒ—ç§‘å¤§": "å¿ å­æ–°ç”Ÿ",

        # ===== äº¤é€šæ¨ç´ (Transportation Hubs) =====
        "å°åŒ—ç«è»Šç«™": "å°åŒ—è»Šç«™",
        "æ¿æ©‹ç«è»Šç«™": "æ¿æ©‹",
        "é«˜éµç«™": "å°åŒ—è»Šç«™",
        "æ¾å±±ç«è»Šç«™": "æ¾å±±",
        "å—æ¸¯ç«è»Šç«™": "å—æ¸¯",

        # ===== å¸¸è¦‹å£èª¤æˆ–è®Šé«” (Common Misspellings / Variants) =====
        "è±¡å±±æ­¥é“": "è±¡å±±",
        "æ±Ÿå­ç¿ ç«™": "æ±Ÿå­ç¿ ",
        "è¬èŠ³": "è¬èŠ³é†«é™¢",
        "å°é›»å¤§æ¨“ç«™": "å°é›»å¤§æ¨“",
        "å¤§å®‰ç«™": "å¤§å®‰",
        "æ°¸æ˜¥ç«™": "æ°¸æ˜¥",
        "å¾Œå±±åŸ¤ç«™": "å¾Œå±±åŸ¤",
        "æ˜†é™½ç«™": "æ˜†é™½",
        "Jhongxiao": "å¿ å­å¾©èˆˆ",
        "CKS Memorial Hall": "ä¸­æ­£ç´€å¿µå ‚",
    }
    
    for alias, primary_name in alias_map.items():
        norm_alias = normalize_name(alias)
        norm_primary = normalize_name(primary_name)
        if norm_primary in station_map:
            station_map[norm_alias] = station_map[norm_primary]

    # 5. æœ€çµ‚è™•ç†èˆ‡å„²å­˜
    station_map_list = {k: sorted(list(v)) for k, v in station_map.items()}
    
    with open(config.STATION_DATA_PATH, 'w', encoding='utf-8') as f:
        json.dump(station_map_list, f, ensure_ascii=False, indent=2)
        
    print(f"--- âœ… ç«™é»è³‡æ–™åº«å»ºç«‹æˆåŠŸï¼Œå…± {len(station_map_list)} å€‹ç«™å/åˆ¥åã€‚ ---")
    time.sleep(1)

def build_fare_database():
    """å¾ TDX API ç²å–æ‰€æœ‰ç¥¨åƒ¹è³‡è¨Šï¼Œä¸¦å„²å­˜ç‚º JSON æª”æ¡ˆã€‚"""
    print("\n--- [2/5] æ­£åœ¨å»ºç«‹ã€Œç¥¨åƒ¹è³‡æ–™åº«ã€... ---")
    tdx_fares = tdx_api.get_all_fares()
    fare_map = {}
    
    if not tdx_fares:
        print("--- âŒ [TDX] å¾ TDX API ç²å–ç¥¨åƒ¹æ•¸æ“šå¤±æ•—æˆ–ç‚ºç©ºï¼å°‡ä¸æœƒå»ºç«‹ç¥¨åƒ¹æª”æ¡ˆã€‚---")
        return 

    print(f"--- [TDX] æˆåŠŸå¾ TDX API ç²å–äº† {len(tdx_fares)} ç­† O-D é…å°åŸå§‹è³‡æ–™ã€‚---")
    for info in tdx_fares:
        o_id = info.get("OriginStationID")
        d_id = info.get("DestinationStationID")
        fares = info.get("Fares", [])
        if o_id and d_id and fares:
            adult_fare = next((f.get("Price") for f in fares if f.get("TicketType") == 1 and f.get("FareClass") == 1), None)
            child_fare = next((f.get("Price") for f in fares if f.get("TicketType") == 1 and f.get("FareClass") == 4), None)
            if adult_fare is not None and child_fare is not None:
                key1 = f"{o_id}-{d_id}"
                key2 = f"{d_id}-{o_id}"
                fare_data = {"å…¨ç¥¨": adult_fare, "å…’ç«¥ç¥¨": child_fare}
                fare_map[key1] = fare_data
                fare_map[key2] = fare_data
    
    os.makedirs(os.path.dirname(config.FARE_DATA_PATH), exist_ok=True)
    with open(config.FARE_DATA_PATH, 'w', encoding='utf-8') as f:
        json.dump(fare_map, f, ensure_ascii=False, indent=2)
    print(f"--- âœ… ç¥¨åƒ¹è³‡æ–™åº«å»ºç«‹æˆåŠŸï¼Œå…±å¯«å…¥ {len(fare_map)} ç­†ç¥¨åƒ¹çµ„åˆã€‚ ---")
    time.sleep(1)

def build_transfer_database():
    """å¾ TDX API ç²å–æ·é‹è½‰ä¹˜è³‡è¨Šï¼Œä¸¦å„²å­˜ç‚º JSON æª”æ¡ˆã€‚"""
    print("\n--- [3/5] æ­£åœ¨å»ºç«‹ã€Œè½‰ä¹˜è³‡æ–™åº«ã€... ---")
    transfer_data = tdx_api.get_line_transfer_info()
    if not transfer_data:
        print("--- âŒ æ­¥é©Ÿ 3 å¤±æ•—: ç„¡æ³•ç²å–è½‰ä¹˜è³‡æ–™ã€‚è«‹æª¢æŸ¥ API é‡‘é‘°èˆ‡ç¶²è·¯ã€‚ ---")
        return

    os.makedirs(os.path.dirname(config.TRANSFER_DATA_PATH), exist_ok=True)
    with open(config.TRANSFER_DATA_PATH, 'w', encoding='utf-8') as f:
        json.dump(transfer_data, f, ensure_ascii=False, indent=2)

    print(f"--- âœ… è½‰ä¹˜è³‡æ–™åº«å»ºç«‹æˆåŠŸï¼Œå…± {len(transfer_data)} ç­†è½‰ä¹˜è³‡è¨Šã€‚ ---")
    time.sleep(1)

# --- âœ¨ã€æ ¸å¿ƒä¿®æ”¹è™•ï¼šå¾ CSV è®€å–è¨­æ–½è³‡æ–™ã€‘âœ¨ ---
def build_facilities_database():
    """
    å¾æ‰‹å‹•ä¸‹è¼‰çš„ mrt_station_facilities_raw.csv è®€å–è©³ç´°è¨­æ–½è³‡è¨Šï¼Œ
    ä¸¦è½‰æ›ç‚º Agent æ‰€éœ€çš„ JSON æ ¼å¼ã€‚
    """
    print("\n--- [5/6] æ­£åœ¨å¾ CSV å»ºç«‹ã€Œè»Šç«™è¨­æ–½è³‡æ–™åº«ã€... ---")
    
    # ã€æ­¥é©Ÿ1 ä¿®æ”¹ã€‘å°‡æª”åæ”¹ç‚ºè‹±æ–‡ï¼Œå¢åŠ å¯è®€æ€§èˆ‡ç›¸å®¹æ€§
    csv_path = os.path.join(config.DATA_DIR, 'mrt_station_facilities_raw.csv')
    station_map_path = config.STATION_DATA_PATH

    if not os.path.exists(csv_path):
        print(f"--- âŒ æ­¥é©Ÿ 5 å¤±æ•—: æ‰¾ä¸åˆ°è¨­æ–½ CSV æª”æ¡ˆ -> {csv_path} ---")
        print("--- ğŸ‘‰ è«‹ç¢ºèªæ‚¨å·²å°‡ä¸‹è¼‰çš„ CSV é‡æ–°å‘½åç‚º mrt_station_facilities_raw.csv ä¸¦æ”¾ç½®åˆ° data è³‡æ–™å¤¾ã€‚ ---")
        return
        
    if not os.path.exists(station_map_path):
        print(f"--- âŒ æ­¥é©Ÿ 5 å¤±æ•—: æ‰¾ä¸åˆ°ç«™é»åœ°åœ–æª”æ¡ˆ -> {station_map_path} ---")
        print("--- ğŸ‘‰ è«‹å…ˆåŸ·è¡Œ `python build_database.py --name stations` ä¾†ç”Ÿæˆæ­¤æª”æ¡ˆã€‚ ---")
        return

    try:
        # è¼‰å…¥ç«™é»åç¨±åˆ° ID çš„æ˜ å°„è¡¨ï¼Œä»¥ä¾¿å°æ‡‰
        with open(station_map_path, 'r', encoding='utf-8') as f:
            station_map = json.load(f)

        # ã€æ­¥é©Ÿ2 ä¿®æ”¹ã€‘è®€å– CSV æ™‚ï¼Œæ˜ç¢ºæŒ‡å®šä½¿ç”¨ 'utf-8' ç·¨ç¢¼ä¾†è§£æ±ºäº‚ç¢¼å•é¡Œ
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        facilities_map = {}
        
        # éæ­· CSV ä¸­çš„æ¯ä¸€è¡Œ
        for _, row in df.iterrows():
            station_name_raw = row.get('è»Šç«™åç¨±')
            if not station_name_raw or pd.isna(station_name_raw):
                continue
            
            # æ¨™æº–åŒ– CSV ä¸­çš„ç«™åï¼Œä»¥ä¾¿åœ¨æˆ‘å€‘çš„ç«™é»åœ°åœ–ä¸­æŸ¥æ‰¾
            norm_name = normalize_name(station_name_raw)
            station_ids = station_map.get(norm_name)
            
            if not station_ids:
                print(f"--- âš ï¸ è­¦å‘Š: åœ¨ç«™é»åœ°åœ–ä¸­æ‰¾ä¸åˆ° '{station_name_raw}' çš„å°æ‡‰ IDï¼Œè·³éæ­¤ç«™è¨­æ–½ã€‚ ---")
                continue

            # å°‡æ‰€æœ‰è¨­æ–½æ¬„ä½çš„è³‡è¨Šæ•´åˆæˆä¸€å€‹æ˜“è®€çš„å­—ä¸²
            info_parts = []
            facility_columns = {
                "é›»æ¢¯": row.get('é›»æ¢¯'), "é›»æ‰¶æ¢¯": row.get('é›»æ‰¶æ¢¯'),
                "éŠ€è¡ŒATM": row.get('éŠ€è¡ŒATM'), "å“ºä¹³å®¤": row.get('å“ºä¹³å®¤'),
                "é£²æ°´æ©Ÿ": row.get('é£²æ°´æ©Ÿ'), "å……é›»ç«™": row.get('å……é›»ç«™'),
                "å»æ‰€": row.get('å»æ‰€')
            }

            for name, value in facility_columns.items():
                if value and not pd.isna(value):
                    # å°‡æ›è¡Œç¬¦è½‰ç‚ºæ˜“è®€æ ¼å¼ï¼Œä¸¦åŠ ä¸Šæ¨™é¡Œ
                    formatted_value = str(value).replace('\n', ', ')
                    info_parts.append(f"ã€{name}ã€‘\n{formatted_value}")
            
            final_info = "\n\n".join(info_parts) if info_parts else "ç„¡è©³ç´°è¨­æ–½è³‡è¨Šã€‚"

            # ç‚ºæ­¤ç«™æ‰€æœ‰å¯èƒ½çš„ ID éƒ½å¡«ä¸Šç›¸åŒçš„è¨­æ–½è³‡è¨Š
            for sid in station_ids:
                facilities_map[sid] = final_info

        # å„²å­˜çµæœ
        with open(config.FACILITIES_DATA_PATH, 'w', encoding='utf-8') as f:
            json.dump(facilities_map, f, ensure_ascii=False, indent=4)

        print(f"--- âœ… è»Šç«™è¨­æ–½è³‡æ–™åº«å·²æˆåŠŸå»ºç«‹ï¼Œå…±è™•ç† {len(facilities_map)} å€‹ç«™é» ID çš„è¨­æ–½è³‡è¨Šã€‚ ---")

    except UnicodeDecodeError:
        print("--- âŒ è®€å– CSV å¤±æ•—ï¼Œä½¿ç”¨ UTF-8 è§£ç¢¼å¤±æ•—ã€‚è«‹å˜—è©¦æ‰‹å‹•ç”¨ VS Code æˆ–è¨˜äº‹æœ¬ç­‰å·¥å…·å°‡ CSV æª”æ¡ˆã€Œå¦å­˜ç‚º UTF-8ã€æ ¼å¼å¾Œå†è©¦ä¸€æ¬¡ã€‚ ---")
    except Exception as e:
        print(f"--- âŒ æ­¥é©Ÿ 5 å¤±æ•—: è™•ç† CSV æˆ–å»ºç«‹ JSON æ™‚ç™¼ç”ŸéŒ¯èª¤: {e} ---")

    time.sleep(1)

def build_exit_database():
    """å¾ TDX API ç²å–è»Šç«™å‡ºå…¥å£è³‡è¨Šï¼Œä¸¦å„²å­˜ç‚º JSON æª”æ¡ˆã€‚"""
    print("\n--- [5/5] æ­£åœ¨å»ºç«‹ã€Œè»Šç«™å‡ºå…¥å£è³‡æ–™åº«ã€... ---")
    
    all_exits_data = tdx_api.get_station_exits(rail_system="TRTC")
    
    if not all_exits_data:
        print("--- âŒ æ­¥é©Ÿ 5 å¤±æ•—: ç„¡æ³•ç²å–è»Šç«™å‡ºå…¥å£è³‡æ–™ã€‚ ---")
        return

    exit_map = {}
    processed_exit_count = 0
    for exit_info in all_exits_data:
        station_id = exit_info.get("StationID")
        exit_no = exit_info.get("ExitID")
        if exit_no is None:
            exit_no = exit_info.get("''ExitID'") 

        exit_description_obj = exit_info.get("ExitDescription", {})
        exit_description = exit_description_obj.get("Zh_tw", "ç„¡æè¿°")
        
        if not (station_id and exit_no):
            print(f"--- âš ï¸ Skipping exit info due to missing StationID or ExitNo: {exit_info} ---")
            continue
        
        if station_id not in exit_map:
            exit_map[station_id] = []
        exit_map[station_id].append({"ExitNo": exit_no, "Description": exit_description.strip()})
        processed_exit_count += 1

    os.makedirs(os.path.dirname(config.EXIT_DATA_PATH), exist_ok=True)
    with open(config.EXIT_DATA_PATH, 'w', encoding='utf-8') as f:
        json.dump(exit_map, f, ensure_ascii=False, indent=4)

    print(f"--- âœ… è»Šç«™å‡ºå…¥å£è³‡æ–™åº«å·²æˆåŠŸå»ºç«‹æ–¼ {config.EXIT_DATA_PATH}ï¼Œå…±åŒ…å« {len(exit_map)} å€‹ç«™é»çš„å‡ºå…¥å£è³‡è¨Šï¼Œç¸½å…±è™•ç†äº† {processed_exit_count} ç­†å‡ºå£è¨˜éŒ„ã€‚ ---")
    time.sleep(1)
    
# --- ã€âœ¨æœ€çµ‚ç°¡åŒ–ç‰ˆâœ¨ã€‘ ---
def build_lost_and_found_database():
    """
    å¾ metro_soap_api ç²å–æ‰€æœ‰éºå¤±ç‰©è³‡è¨Šï¼Œä¸¦å„²å­˜ç‚º JSON æª”æ¡ˆã€‚
    """
    print("\n--- [6/6] æ­£åœ¨å»ºç«‹ã€Œéºå¤±ç‰©è³‡æ–™åº«ã€... ---")
    
    try:
        # ç›´æ¥å‘¼å«æˆ‘å€‘åœ¨ MetroSoapApi ä¸­å»ºç«‹å¥½çš„æ–°æ–¹æ³•
        items = metro_soap_api.get_all_lost_items()

        # æª¢æŸ¥ API å‘¼å«æ˜¯å¦æˆåŠŸ
        if items is None: # å¦‚æœ get_all_lost_items å›å‚³ Noneï¼Œä»£è¡¨å‘¼å«å¤±æ•—
            print("--- âŒ æ­¥é©Ÿ 6 å¤±æ•—: å¾ metro_soap_api ç²å–éºå¤±ç‰©è³‡æ–™å¤±æ•—ã€‚è«‹æª¢æŸ¥æ—¥èªŒã€‚ ---")
            return

        # å°‡ç²å–çš„è³‡æ–™å¯«å…¥æœ¬åœ°æª”æ¡ˆ
        with open(config.LOST_AND_FOUND_DATA_PATH, 'w', encoding='utf-8') as f:
            json.dump(items, f, ensure_ascii=False, indent=2)

        print(f"--- âœ… éºå¤±ç‰©è³‡æ–™åº«å»ºç«‹æˆåŠŸï¼Œå…±å¯«å…¥ {len(items)} ç­†è³‡æ–™ã€‚ ---")

    except Exception as e:
        print(f"--- âŒ æ­¥é©Ÿ 6 å¤±æ•—: å»ºç«‹éºå¤±ç‰©è³‡æ–™åº«æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e} ---")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Build local databases for the MetroPet AI Agent.")
    parser.add_argument(
        "--name", 
        type=str,
        default="all",
        choices=["stations", "fares", "transfers", "facilities", "exits", "lost_and_found", "all"],
        help="Specify which database to build. Use 'all' to build everything."
    )
    args = parser.parse_args()

    if args.name == "all":
        print("--- æ­£åœ¨é–‹å§‹å»ºç«‹æ‰€æœ‰æœ¬åœ°è³‡æ–™åº«ï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“... ---")
        build_station_database()
        build_fare_database()
        build_transfer_database()
        build_facilities_database()
        build_exit_database()
        build_lost_and_found_database()
        print("\n--- âœ… æ‰€æœ‰æœ¬åœ°è³‡æ–™åº«å»ºç«‹å®Œæˆï¼ ---")
    
    elif args.name == "stations":
        build_station_database()
    elif args.name == "fares":
        build_fare_database()
    elif args.name == "transfers":
        build_transfer_database()
    elif args.name == "facilities":
        build_facilities_database()
    elif args.name == "exits":
        build_exit_database()
    elif args.name == "lost_and_found":
        build_lost_and_found_database()