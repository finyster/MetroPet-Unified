# build_lost_item_index.py
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import config
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def build_lost_item_index():
    logger.info("--- ğŸš€ é–‹å§‹å»ºç«‹ã€éºå¤±ç‰©åç¨±ã€‘å‘é‡ç´¢å¼• ---")

    with open(config.LOST_AND_FOUND_DATA_PATH, 'r', encoding='utf-8') as f:
        lost_items_data = json.load(f)

    # åªå–å‡ºæ‰€æœ‰ä¸é‡è¤‡çš„ç‰©å“åç¨±ä¾†å»ºç«‹ç´¢å¼•
    item_names = sorted(list(set(item['col_LoseName'] for item in lost_items_data)))

    logger.info(f"âœ… æˆåŠŸè¼‰å…¥ {len(item_names)} å€‹ä¸é‡è¤‡çš„éºå¤±ç‰©åç¨±ã€‚")

    logger.info("â³ æ­£åœ¨è¼‰å…¥èªæ„æ¨¡å‹...")
    model = SentenceTransformer('distiluse-base-multilingual-cased-v1')
    logger.info("âœ… èªæ„æ¨¡å‹è¼‰å…¥æˆåŠŸã€‚")

    logger.info("â³ æ­£åœ¨å°‡æ‰€æœ‰ç‰©å“åç¨±ç·¨ç¢¼ç‚ºå‘é‡...")
    item_embeddings = model.encode(item_names, convert_to_tensor=False, show_progress_bar=True)
    item_embeddings = np.array(item_embeddings).astype('float32')

    embedding_dimension = item_embeddings.shape[1]
    index = faiss.IndexFlatL2(embedding_dimension)
    index.add(item_embeddings)

    faiss_index_path = os.path.join(config.DATA_DIR, 'lost_item_vector.index')
    names_path = os.path.join(config.DATA_DIR, 'lost_item_names.json')

    faiss.write_index(index, faiss_index_path)
    with open(names_path, 'w', encoding='utf-8') as f:
        json.dump(item_names, f, ensure_ascii=False, indent=2)

    logger.info(f"--- ğŸ‰ æˆåŠŸï¼éºå¤±ç‰©å‘é‡ç´¢å¼•å·²å„²å­˜ã€‚ ---")

if __name__ == "__main__":
    build_lost_item_index()