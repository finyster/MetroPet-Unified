import pandas as pd
import xgboost as xgb
import joblib
import os
import logging
import json
from typing import Dict, Any, Optional, Tuple

# --- å‹•æ…‹è·¯å¾‘è¨­ç½® ---
# é€™æ˜¯ç‚ºäº†ç¢ºä¿ç„¡è«–å¦‚ä½•åŸ·è¡Œï¼Œéƒ½èƒ½æ‰¾åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„æ¨¡çµ„
import sys
# ç²å–ç•¶å‰è…³æœ¬ prediction_service.py çš„çµ•å°è·¯å¾‘
# os.path.abspath(__file__) -> D:\...\services\prediction_service.py
# os.path.dirname(...)      -> D:\...\services
# os.path.dirname(...)      -> D:\...\ (å°ˆæ¡ˆæ ¹ç›®éŒ„)
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

# ç¾åœ¨å¯ä»¥å®‰å…¨åœ°å¾æ ¹ç›®éŒ„åŒ¯å…¥
from services.station_service import StationManager
import config # å‡è¨­ config.py åœ¨æ ¹ç›®éŒ„

# --- é…ç½®æ—¥èªŒ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ... (æ‚¨çš„ CongestionPredictor é¡åˆ¥å®šç¾©ç¶­æŒä¸è®Š) ...

class CongestionPredictor:
    def __init__(self, station_manager_instance: StationManager):
        logger.info("--- [Predictor] æ­£åœ¨åˆå§‹åŒ–äººæµé æ¸¬æœå‹™... ---")
        self.station_manager = station_manager_instance
        self.models: Dict[str, xgb.XGBRegressor] = {}
        self.encoders: Dict[str, any] = {}
        self.feature_columns: Dict[str, list] = {}
        self.is_ready = self._load_all_models()

        if self.is_ready:
            logger.info("--- âœ… é æ¸¬æœå‹™å·²æˆåŠŸè¼‰å…¥æ¨¡å‹ä¸¦æº–å‚™å°±ç·’ã€‚ ---")
        else:
            logger.error("--- âŒ é æ¸¬æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼Œéƒ¨åˆ†æ¨¡å‹æˆ–æª”æ¡ˆç¼ºå¤±ã€‚ ---")

    def _load_all_models(self) -> bool:
        """è¼‰å…¥æ‰€æœ‰ç·šè·¯é¡å‹çš„æ¨¡å‹ã€ç·¨ç¢¼å™¨å’Œç‰¹å¾µåˆ—è¡¨ã€‚"""
        all_loaded = True
        for line_type in ['high_capacity', 'wenhu']:
            data_dir = os.path.join(project_root, 'data')
            model_path = os.path.join(data_dir, f'{line_type}_congestion_model.json')
            encoder_path = os.path.join(data_dir, f'{line_type}_encoder.joblib')
            features_path = os.path.join(data_dir, f'{line_type}_feature_columns.csv')
            
            if not all(os.path.exists(p) for p in [model_path, encoder_path, features_path]):
                logger.warning(f"--- âš ï¸ æ‰¾ä¸åˆ° {line_type} çš„æ¨¡å‹æª”æ¡ˆï¼Œè«‹å…ˆé‹è¡Œ model_trainer.pyã€‚ ---")
                all_loaded = False
                continue
            
            self.models[line_type] = xgb.XGBRegressor()
            self.models[line_type].load_model(model_path)
            self.encoders[line_type] = joblib.load(encoder_path)
            self.feature_columns[line_type] = pd.read_csv(features_path)['feature'].tolist()
            logger.info(f"--- âœ… å·²æˆåŠŸè¼‰å…¥ {line_type} æ¨¡å‹ã€‚ ---")
        return all_loaded

    def _get_line_type_and_id(self, station_name: str) -> Optional[Tuple[str, str]]:
        """æ ¹æ“šç«™åç²å–ç·šè·¯é¡å‹å’Œæ¨™æº–ç«™é» IDã€‚"""
        # ä¿®æ­£ï¼šå‘¼å«æ­£ç¢ºçš„æ–¹æ³• get_station_idsï¼Œå®ƒæœƒè¿”å›ä¸€å€‹ ID åˆ—è¡¨
        station_ids = self.station_manager.get_station_ids(station_name)
        
        # å¦‚æœæ‰¾ä¸åˆ° ID æˆ–åˆ—è¡¨ç‚ºç©ºï¼Œå‰‡è¨˜éŒ„è­¦å‘Šä¸¦è¿”å›
        if not station_ids:
            logger.warning(f"ç„¡æ³•åœ¨ StationManager ä¸­æ‰¾åˆ°ç«™å '{station_name}' çš„ä»»ä½• IDã€‚")
            return None, None
            
        # ç­–ç•¥ï¼šä½¿ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹ ID ä¾†åˆ¤æ–·è·¯ç·šé¡å‹å’Œé€²è¡Œå¾ŒçºŒé æ¸¬ã€‚
        # å°æ–¼è½‰ä¹˜ç«™ï¼ˆå¦‚ï¼šå—äº¬å¾©èˆˆ BR11, G16ï¼‰ï¼Œå–ç¬¬ä¸€å€‹ ID (BR11) å·²è¶³å¤ ã€‚
        station_id = station_ids[0]
        
        # ç°¡æ˜“åˆ¤æ–·ï¼šæ–‡æ¹–ç·š ID ä»¥ 'BR' é–‹é ­
        if station_id.startswith('BR'):
            return 'wenhu', station_id
        return 'high_capacity', station_id

    def _create_prediction_features(self, station_id: str, line_direction_cid: int, line_type: str) -> pd.DataFrame:
        """
        ã€æ ¸å¿ƒé æ¸¬ç‰¹å¾µå‰µå»ºã€‘
        ç‚ºå–®æ¬¡é æ¸¬å‰µå»ºèˆ‡è¨“ç·´æ™‚å®Œå…¨ä¸€è‡´çš„ç‰¹å¾µã€‚
        æ³¨æ„ï¼šé€™è£¡çš„æ»¯å¾Œç‰¹å¾µæ˜¯ç°¡åŒ–è™•ç†çš„ï¼ŒçœŸå¯¦ä¸Šç·šç³»çµ±éœ€è¦ feature storeã€‚
        """
        now = pd.Timestamp.now()
        
        # æ¨¡æ“¬æ»¯å¾Œç‰¹å¾µï¼Œé€™è£¡ç”¨ 0 ä½œç‚ºç°¡åŒ–
        # åœ¨çœŸå¯¦ç³»çµ±ä¸­ï¼Œé€™è£¡æ‡‰è©²å¾å¿«å–æˆ–è³‡æ–™åº«ä¸­è®€å–æœ€è¿‘çš„çœŸå¯¦æ“æ“ åº¦
        lag_5min_congestion = 0.0
        lag_1hr_congestion = 0.0
        
        num_cars = 4 if line_type == 'wenhu' else 6
        records = []
        for car_num in range(1, num_cars + 1):
            records.append({
                'station_id': station_id,
                'line_direction_cid': str(line_direction_cid),
                'hour': now.hour,
                'day_of_week': now.dayofweek,
                'is_weekend': int(now.dayofweek >= 5),
                'car_number': car_num,
                'lag_5min_congestion': lag_5min_congestion,
                'lag_1hr_congestion': lag_1hr_congestion
            })
        
        df_raw = pd.DataFrame(records)
        
        # ä½¿ç”¨å·²è¼‰å…¥çš„ç·¨ç¢¼å™¨é€²è¡Œ OneHot ç·¨ç¢¼
        encoder = self.encoders[line_type]
        categorical_features = ['station_id', 'line_direction_cid']
        encoded_data = encoder.transform(df_raw[categorical_features])
        encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_features))
        
        # çµ„åˆæ‰€æœ‰ç‰¹å¾µ
        numeric_features = ['hour', 'day_of_week', 'is_weekend', 'car_number', 'lag_5min_congestion', 'lag_1hr_congestion']
        final_df = pd.concat([df_raw[numeric_features].reset_index(drop=True), encoded_df], axis=1)
        
        # ç¢ºä¿ç‰¹å¾µé †åºèˆ‡è¨“ç·´æ™‚å®Œå…¨ä¸€è‡´
        final_df = final_df.reindex(columns=self.feature_columns[line_type], fill_value=0)
        
        return final_df

    def predict_for_station(self, station_name: str, direction: str) -> Dict[str, Any]:
        """
        ã€å°å¤–é æ¸¬ä»‹é¢ã€‘
        æ¥æ”¶ä½¿ç”¨è€…æ˜“æ–¼ç†è§£çš„ç«™åå’Œæ–¹å‘ï¼Œè¿”å›é æ¸¬çµæœã€‚
        """
        if not self.is_ready:
            return {"error": "é æ¸¬æœå‹™å°šæœªæº–å‚™å°±ç·’ï¼Œè«‹æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚"}

        line_type, station_id = self._get_line_type_and_id(station_name)
        if not line_type:
            return {"error": f"ç„¡æ³•è­˜åˆ¥è»Šç«™ '{station_name}'ï¼Œè«‹ç¢ºèªç«™åæ˜¯å¦æ­£ç¢ºã€‚"}
            
        # å°‡æ–¹å‘æ–‡å­—è½‰æ›ç‚ºæ•¸å­— ID (ä¸Šè¡Œ/ä¸‹è¡Œ)ï¼Œé€™è£¡éœ€è¦ä¸€å€‹æ˜ç¢ºçš„æ˜ å°„è¦å‰‡
        # å‡è¨­: ä¸Šè¡Œ=1, ä¸‹è¡Œ=2ã€‚é€™éœ€è¦æ ¹æ“š API çš„å¯¦éš›å®šç¾©èª¿æ•´ã€‚
        direction_map = {"ä¸Šè¡Œ": 1, "å¾€å—æ¸¯å±•è¦½é¤¨": 1, "å¾€å‹•ç‰©åœ’": 1, "ä¸‹è¡Œ": 2, "å¾€é ‚åŸ”": 2, "å¾€è±¡å±±": 2}
        line_direction_cid = direction_map.get(direction, 1) # é è¨­ç‚º1

        logger.info(f"é–‹å§‹ç‚ºè»Šç«™ '{station_name}' (ID: {station_id}, æ–¹å‘: {line_direction_cid}) é€²è¡Œé æ¸¬...")
        
        try:
            X_pred = self._create_prediction_features(station_id, line_direction_cid, line_type)
            model = self.models[line_type]
            predictions = model.predict(X_pred)
            
            # å°‡çµæœæ ¼å¼åŒ–ç‚ºå‹å–„çš„è¼¸å‡º
            congestion_map = {1: "èˆ’é©", 2: "æ­£å¸¸", 3: "ç•¥å¤š", 4: "æ“æ“ ", 5: "éå¸¸æ“æ“ "}
            results = []
            for i, pred in enumerate(predictions):
                # å°‡é æ¸¬å€¼é™åˆ¶åœ¨ 1-5 ä¹‹é–“ä¸¦å–æ•´
                level = max(1, min(5, round(float(pred))))
                results.append({
                    "car_number": i + 1,
                    "congestion_level": level,
                    "congestion_text": congestion_map.get(level, "æœªçŸ¥")
                })

            return {
                "station_name": station_name,
                "direction": direction,
                "prediction_time": pd.Timestamp.now().isoformat(),
                "congestion_by_car": results,
                "message": f"é æ¸¬ã€Œ{station_name}ã€ç«™å¾€ã€Œ{direction}ã€æ–¹å‘çš„åˆ—è»Šï¼Œå„è»Šå»‚æ“æ“ åº¦å¦‚ä¸‹ã€‚"
            }

        except Exception as e:
            logger.error(f"ç‚º '{station_name}' é€²è¡Œé æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return {"error": f"é æ¸¬æ™‚ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æ—¥èªŒã€‚"}

# --- å¦‚ä½•åœ¨ä¸»æ‡‰ç”¨ä¸­æ•´åˆ ---
# 1. åœ¨ services/__init__.py çš„ ServiceRegistry ä¸­:
#    from .prediction_service import CongestionPredictor
#    self.congestion_predictor = CongestionPredictor(station_manager_instance=self.station_manager)
#
# 2. åœ¨ agent/function_tools.py ä¸­å»ºç«‹å·¥å…·:
#    @tool
#    def predict_congestion(station_name: str, direction: str) -> str:
#        """é æ¸¬æŒ‡å®šè»Šç«™ã€æŒ‡å®šæ–¹å‘çš„åˆ—è»Šè»Šå»‚æ“æ“ ç¨‹åº¦ã€‚"""
#        predictor = service_registry_instance.get_congestion_predictor()
#        result = predictor.predict_for_station(station_name, direction)
#        return json.dumps(result, ensure_ascii=False)
# ==============================================================================
# --- ä¸»ç¨‹å¼åŸ·è¡Œå€å¡Š ---
# ==============================================================================
if __name__ == "__main__":
    """
    é€™å€‹å€å¡Šè®“ prediction_service.py å¯ä»¥è¢«ç›´æ¥åŸ·è¡Œä»¥é€²è¡Œæ¸¬è©¦ã€‚
    å®ƒæœƒæ¨¡æ“¬å»ºç«‹ä¾è³´ç‰©ä»¶ã€åˆå§‹åŒ–é æ¸¬å™¨ï¼Œä¸¦å‘¼å«é æ¸¬åŠŸèƒ½ã€‚
    """
    logger.info("--- [ä¸»ç¨‹å¼] é–‹å§‹åŸ·è¡Œé æ¸¬æœå‹™ç¨ç«‹æ¸¬è©¦ ---")
    
    # 1. å®šç¾©å¿…è¦çš„æª”æ¡ˆè·¯å¾‘ (ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„)
    #    project_root å·²åœ¨æª”æ¡ˆé ‚éƒ¨å®šç¾©
    station_info_path = os.path.join(project_root, 'data', 'mrt_station_info.json')

    logger.info(f"--- [ä¸»ç¨‹å¼] ä½¿ç”¨ç«™é»è³‡æ–™è·¯å¾‘: {station_info_path}")

    if not os.path.exists(station_info_path):
        logger.error(f"--- âŒ [ä¸»ç¨‹å¼] è‡´å‘½éŒ¯èª¤: æ‰¾ä¸åˆ°ç«™é»è³‡æ–™æª”æ¡ˆ '{station_info_path}'ã€‚")
    else:
        try:
            # 2. å»ºç«‹ StationManager çš„å¯¦ä¾‹
            #    å‡è¨­ StationManager çš„ __init__ éœ€è¦ station_data_path
            station_manager = StationManager(station_data_path=station_info_path)
            logger.info("--- âœ… [ä¸»ç¨‹å¼] StationManager å¯¦ä¾‹å»ºç«‹æˆåŠŸã€‚ ---")

            # 3. å»ºç«‹ CongestionPredictor çš„å¯¦ä¾‹
            predictor = CongestionPredictor(station_manager_instance=station_manager)
            
            # 4. æª¢æŸ¥é æ¸¬å™¨æ˜¯å¦å·²æº–å‚™å°±ç·’ (æ¨¡å‹æ˜¯å¦éƒ½è¼‰å…¥æˆåŠŸ)
            if predictor.is_ready:
                logger.info("--- âœ… [ä¸»ç¨‹å¼] CongestionPredictor å¯¦ä¾‹å»ºç«‹æˆåŠŸä¸¦æº–å‚™å°±ç·’ã€‚ ---")
                
                # 5. âœ¨âœ¨âœ¨ åŸ·è¡Œé æ¸¬ï¼ âœ¨âœ¨âœ¨
                print("\n" + "="*60)
                print("                     ğŸš‡ MetroPet å³æ™‚é æ¸¬ç¯„ä¾‹ ğŸš‡")
                print("="*60 + "\n")
                
                # --- æ¸¬è©¦æ¡ˆä¾‹ 1: é«˜é‹é‡è»Šç«™ (æ¿å—ç·š) ---
                station_1 = "å¸‚æ”¿åºœ"
                direction_1 = "å¾€å—æ¸¯å±•è¦½é¤¨"
                logger.info(f"--- [é æ¸¬ 1] æ­£åœ¨é æ¸¬ [{station_1}] å¾€ [{direction_1}] æ–¹å‘...")
                prediction_1 = predictor.predict_for_station(station_1, direction_1)
                print(json.dumps(prediction_1, indent=2, ensure_ascii=False))

                print("\n" + "-"*60 + "\n")

                # --- æ¸¬è©¦æ¡ˆä¾‹ 2: æ–‡æ¹–ç·šè»Šç«™ ---
                station_2 = "å—äº¬å¾©èˆˆ"
                direction_2 = "å¾€å‹•ç‰©åœ’"
                logger.info(f"--- [é æ¸¬ 2] æ­£åœ¨é æ¸¬ [{station_2}] å¾€ [{direction_2}] æ–¹å‘...")
                prediction_2 = predictor.predict_for_station(station_2, direction_2)
                print(json.dumps(prediction_2, indent=2, ensure_ascii=False))
                
                print("\n" + "="*60)
                logger.info("--- [ä¸»ç¨‹å¼] æ‰€æœ‰é æ¸¬ç¯„ä¾‹åŸ·è¡Œå®Œç•¢ã€‚ ---")
            else:
                logger.error("--- âŒ [ä¸»ç¨‹å¼] é æ¸¬å™¨æœªæº–å‚™å°±ç·’ã€‚è«‹æª¢æŸ¥ data è³‡æ–™å¤¾ä¸­çš„æ¨¡å‹ç›¸é—œæª”æ¡ˆã€‚")

        except Exception as e:
            import traceback
            logger.error(f"--- âŒ [ä¸»ç¨‹å¼] åŸ·è¡Œéç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e} ---")
            traceback.print_exc()